{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda9bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/miniconda3/envs/fairmof/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_pyg_obj\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import fix_target_shapes,remove_unused_onehot_columns,set_seed,filter_metals\n",
    "from mofstructure import mofdeconstructor\n",
    "\n",
    "from fairmofsyncondition.read_write.coords_library import pytorch_geometric_to_ase\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "\n",
    "convert_struct = {'cubic':0, 'hexagonal':1, 'monoclinic':2, 'orthorhombic':3, 'tetragonal':4,'triclinic':5, 'trigonal':6}\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a212130",
   "metadata": {},
   "source": [
    "# GNN for Metal Salt Prediction\n",
    "\n",
    "This code implements a **Graph Neural Network (GNN)** to predict metal salts, using:\n",
    "- **Node Features**  \n",
    "- **Edge Features**  \n",
    "- **Lattice**   \n",
    "- **Oms**\n",
    "- **Atomic number**\n",
    "---\n",
    "\n",
    "## Code Structure\n",
    "\n",
    "1. **Load the Data**  \n",
    "   Import and prepare the dataset for use in the model.\n",
    "\n",
    "2. **Define the GNN Model**  \n",
    "   Define the neural network architecture (layers, activation functions, etc.).\n",
    "\n",
    "3. **Train the Model**  \n",
    "   - Train the model on the dataset.  \n",
    "   - Save the trained GNN weights into the `tmp/` folder.  \n",
    "\n",
    "   ⚠️ **Note**:  \n",
    "   If you only want to **test the model** without re-training, you can **skip this section** and avoid running the training step.\n",
    "\n",
    "4. **Load and Evaluate the Model**  \n",
    "   - Load the trained model weights.  \n",
    "   - Evaluate the model performance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afb0dd",
   "metadata": {},
   "source": [
    "### 1) Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d29a2",
   "metadata": {},
   "source": [
    "\n",
    "### to get oms\n",
    "### stru.get_oms()[\"has_oms\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17366789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mofstructure.structure import MOFstructure\n",
    "# convert_metals = {j:i for i,j in enumerate(mofdeconstructor.transition_metals()[1:])}\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# set_seed(seed=42)\n",
    "\n",
    "# data_in = load_pyg_obj(path_to_mdb=\"../../data/mof_syncondition_data/\")\n",
    "# dataset = fix_target_shapes(data_in, \"metal_salts\")\n",
    "# dataset = remove_unused_onehot_columns(dataset, \"metal_salts\")\n",
    "\n",
    "\n",
    "# bad = []\n",
    "# good = []\n",
    "\n",
    "# c = 0\n",
    "# for d in dataset:\n",
    "#     if c % 100 == 0:\n",
    "#         print(c)\n",
    "#     c = c + 1\n",
    "\n",
    "#     try:\n",
    "#         # =======================\n",
    "#         # Parte 1: atomic one-hot\n",
    "#         # =======================\n",
    "#         node_features = d.x.numpy()\n",
    "#         atom_num = node_features[:, 0].astype(int)\n",
    "#         a, b = np.unique(atom_num, return_counts=True)\n",
    "#         emb = torch.zeros(120)\n",
    "#         for aa, bb in zip(a, b):\n",
    "#             emb[aa] = bb\n",
    "#         d.atomic_one_hot = emb\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 2: struttura ASE\n",
    "#         # =======================\n",
    "#         ase_atoms = pytorch_geometric_to_ase(d)\n",
    "#         stru = MOFstructure(ase_atoms)\n",
    "#         pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 3: OMS\n",
    "#         # =======================\n",
    "#         emb = torch.zeros(96)\n",
    "#         tmp_dict = dict()\n",
    "#         for i in stru.get_oms()[\"metal_info\"]:\n",
    "#             cord = i[\"coordination_number\"]\n",
    "#             metal = i[\"metal\"]\n",
    "\n",
    "#             if metal in tmp_dict:\n",
    "#                 if cord > tmp_dict[metal]:\n",
    "#                     tmp_dict[metal] = cord\n",
    "#             else:\n",
    "#                 tmp_dict[metal] = cord\n",
    "\n",
    "#         for i, j in tmp_dict.items():\n",
    "#             emb[convert_metals[i]] = j\n",
    "#         d.cordinates = emb\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 4: spazio e sistema cristallino\n",
    "#         # =======================\n",
    "#         sga = SpacegroupAnalyzer(pymat)\n",
    "#         space_group_number = sga.get_space_group_number()\n",
    "#         emb = torch.zeros(231)\n",
    "#         emb[space_group_number] = 1\n",
    "#         d.space_group_number = emb\n",
    "\n",
    "#         get_crystal_system = sga.get_crystal_system()\n",
    "#         emb = torch.zeros(7)\n",
    "#         emb[convert_struct[get_crystal_system]] = 1\n",
    "#         d.crystal_system = emb\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 5: altri attributi\n",
    "#         # =======================\n",
    "#         d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "#         por = stru.get_porosity()\n",
    "#         por = list(por.values())\n",
    "#         d.porosity = torch.tensor(por)\n",
    "\n",
    "#         d.modified_scherrer = None\n",
    "#         d.microstrain = None\n",
    "\n",
    "#         # Se arrivo qui senza eccezioni → struttura buona\n",
    "#         good.append(d)\n",
    "\n",
    "#     except Exception:\n",
    "#         bad.append(d)\n",
    "#         continue\n",
    "\n",
    "\n",
    "# import torch\n",
    "\n",
    "# torch.save(good, \"dataset_cleen_all_info.pt\")   # salva lista di Data\n",
    "# # poi\n",
    "# dataset = torch.load(\"dataset_cleen_all_info.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283701e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ec87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are classes 122 3054\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ==================== Utils & setup ====================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random, os\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "dataset = torch.load(\"dataset_cleen_all_info.pt\")\n",
    "\n",
    "# Filtra classi rare (come nel tuo codice)\n",
    "Y = [d.metal_salts.argmax(dim=1).item() for d in dataset]\n",
    "a,b = np.unique(Y, return_counts=True)\n",
    "conv_y = {i:j for i,j in zip(a,b)}\n",
    "good = [d for d in dataset if conv_y[d.metal_salts.argmax(dim=1).item()] > 5]\n",
    "dataset = good\n",
    "\n",
    "print(\"There are classes\", len(np.unique([d.metal_salts.argmax(dim=1).item() for d in dataset])), len(dataset))\n",
    "\n",
    "# Split & loaders\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=128)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=128)\n",
    "\n",
    "# ==================== NEW: ablation helpers ====================\n",
    "\n",
    "# 1) Getter per ciascuna feature extra (sempre reshaped a [B, D])\n",
    "#    Aggiungi qui dentro eventuali nuove feature future.\n",
    "\n",
    "def _reshape_feat(tensor, d):\n",
    "    # Se è Batch (ha num_graphs)\n",
    "    if hasattr(d, \"num_graphs\"):\n",
    "        return tensor.view(d.num_graphs, -1)\n",
    "    else:  # è un singolo Data\n",
    "        return tensor.view(1, -1)\n",
    "\n",
    "EXTRA_GETTERS = {\n",
    "    \"atomic_one_hot\":      lambda d: _reshape_feat(d.atomic_one_hot, d),\n",
    "    \"space_group_number\":  lambda d: _reshape_feat(d.space_group_number, d),\n",
    "    \"crystal_system\":      lambda d: _reshape_feat(d.crystal_system, d),\n",
    "    \"oms\":                 lambda d: _reshape_feat(d.oms, d),\n",
    "    \"porosity\":            lambda d: _reshape_feat(d.porosity, d),\n",
    "    \"cordinates\":          lambda d: _reshape_feat(d.cordinates, d),\n",
    "}\n",
    "def compute_extras_dim(sample_data, selected_extras):\n",
    "    dim = 0\n",
    "    for name in selected_extras:\n",
    "        if name not in EXTRA_GETTERS:\n",
    "            raise ValueError(f\"Feature extra sconosciuta: {name}\")\n",
    "        dim += EXTRA_GETTERS[name](sample_data).shape[1]\n",
    "    return dim\n",
    "\n",
    "def build_extras_tensor(data, selected_extras):\n",
    "    if not selected_extras:\n",
    "        return None\n",
    "    parts = [EXTRA_GETTERS[name](data) for name in selected_extras]\n",
    "    return torch.cat(parts, dim=1)\n",
    "\n",
    "def extras_suffix(selected_extras):\n",
    "    if not selected_extras:\n",
    "        return \"no_extras\"\n",
    "    return \"_\".join(selected_extras)\n",
    "\n",
    "# ==================== Model ====================\n",
    "\n",
    "class MetalSaltGNN_Ablation(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in_dim,\n",
    "        edge_in_dim,\n",
    "        lattice_in_dim=9,\n",
    "        hidden_dim=128,\n",
    "        num_classes=10,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=0.2,\n",
    "        use_batchnorm=True,\n",
    "        selected_extras=None,      # NEW: lista di nomi feature extra\n",
    "        extras_dim=0               # NEW: dimensione totale delle extra\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.dropout = dropout\n",
    "        self.selected_extras = selected_extras or []\n",
    "        self.extras_dim = extras_dim\n",
    "\n",
    "        # --- Edge encoder (per GINE)\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # --- GINE layers\n",
    "        self.gnn_layers = nn.ModuleList()\n",
    "        self.gnn_bns = nn.ModuleList() if use_batchnorm else None\n",
    "        for i in range(num_gnn_layers):\n",
    "            in_dim = node_in_dim if i == 0 else hidden_dim\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.gnn_layers.append(GINEConv(mlp, edge_dim=hidden_dim))\n",
    "            if use_batchnorm:\n",
    "                self.gnn_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # --- Lattice encoder\n",
    "        lattice_layers = []\n",
    "        in_dim = lattice_in_dim\n",
    "        for _ in range(max(1, num_lattice_layers - 1)):\n",
    "            lattice_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                lattice_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            in_dim = hidden_dim\n",
    "        lattice_layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.lattice_encoder = nn.Sequential(*lattice_layers)\n",
    "\n",
    "        # --- Final MLP head\n",
    "        final_in = hidden_dim * 2 + self.extras_dim  # graph pooled + lattice + extras\n",
    "        mlp_layers = []\n",
    "        in_dim = final_in\n",
    "        for _ in range(max(1, num_mlp_layers - 1)):\n",
    "            mlp_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                mlp_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            mlp_layers.append(nn.Dropout(p=dropout))\n",
    "            in_dim = hidden_dim\n",
    "        mlp_layers.append(nn.Linear(in_dim, num_classes))\n",
    "        self.final_mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # Encode edges\n",
    "        e = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # GNN layers\n",
    "        for i, conv in enumerate(self.gnn_layers):\n",
    "            x = conv(x, edge_index, e)\n",
    "            x = F.relu(x)\n",
    "            if self.use_batchnorm:\n",
    "                x = self.gnn_bns[i](x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Global pooling\n",
    "        x_pool = global_mean_pool(x, batch)\n",
    "\n",
    "        # Lattice encoding (sempre usato)\n",
    "        lattice = data.lattice.view(-1, 9)\n",
    "        lattice_feat = self.lattice_encoder(lattice)\n",
    "\n",
    "        # Extras (abilitate in base alla lista)\n",
    "        extras = build_extras_tensor(data, self.selected_extras)\n",
    "        if extras is not None:\n",
    "            final_in = torch.cat([x_pool, lattice_feat, extras], dim=1)\n",
    "        else:\n",
    "            final_in = torch.cat([x_pool, lattice_feat], dim=1)\n",
    "\n",
    "        out = self.final_mlp(final_in)\n",
    "        return out\n",
    "\n",
    "# ==================== Train / Eval helpers ====================\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, target_name):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        target = torch.argmax(data[target_name], dim=1).long()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, target_name):\n",
    "    model.eval()\n",
    "    correct = {1: 0, 3: 0, 5: 0, 10: 0}\n",
    "    total = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        labels = torch.argmax(data[target_name], dim=1).long()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        _, pred = logits.topk(10, dim=1)\n",
    "        for k in correct.keys():\n",
    "            correct[k] += (pred[:, :k] == labels.view(-1, 1)).any(dim=1).sum().item()\n",
    "\n",
    "        top1_preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(top1_preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    macro_f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average=\"macro\")\n",
    "\n",
    "    results = {f\"top{k}_acc\": correct[k] / max(1, total) for k in correct}\n",
    "    results[\"macro_f1\"] = macro_f1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b26659",
   "metadata": {},
   "source": [
    "### 2) Define the GNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59c9e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atomic_one_hot',\n",
       " 'cordinates',\n",
       " 'crystal_system',\n",
       " 'oms',\n",
       " 'porosity',\n",
       " 'space_group_number']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==================== Run ablation ====================\n",
    "\n",
    "node_in_dim = dataset[0].x.shape[1]\n",
    "edge_in_dim = dataset[0].edge_attr.shape[1]\n",
    "lattice_in_dim = 9\n",
    "\n",
    "# Scegli qui le extra da usare nell’ablation:\n",
    "# Esempio richiesto: [\"oms\", \"atomic_one_hot\"]\n",
    "\n",
    "\n",
    "EXTRA_GETTERS = {\n",
    "    \"atomic_one_hot\":      lambda d: _reshape_feat(d.atomic_one_hot, d),\n",
    "    \"space_group_number\":  lambda d: _reshape_feat(d.space_group_number, d),\n",
    "    \"crystal_system\":      lambda d: _reshape_feat(d.crystal_system, d),\n",
    "    \"oms\":                 lambda d: _reshape_feat(d.oms, d),\n",
    "    \"porosity\":            lambda d: _reshape_feat(d.porosity, d),\n",
    "    \"cordinates\":          lambda d: _reshape_feat(d.cordinates, d),\n",
    "}\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\", \"oms\",\"space_group_number\",\"crystal_system\",\"porosity\",\"cordinates\"]\n",
    "#selected_extras = [\"atomic_one_hot\", \"oms\"]\n",
    "\n",
    "\n",
    "# imoprtant: for saving\n",
    "selected_extras = np.sort(selected_extras).tolist()\n",
    "selected_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0139d6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training config: HID64_DO0.35_SEED1__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number =====\n",
      "VAL: top1_acc=0.2525, top5_acc=0.4754, top3_acc=0.4098 macro_f1=0.0398\n",
      "VAL: top1_acc=0.4000, top5_acc=0.6459, top3_acc=0.5672 macro_f1=0.0921\n",
      "VAL: top1_acc=0.4426, top5_acc=0.7082, top3_acc=0.6131 macro_f1=0.1259\n",
      "VAL: top1_acc=0.4656, top5_acc=0.7115, top3_acc=0.6459 macro_f1=0.1435\n",
      "VAL: top1_acc=0.4721, top5_acc=0.7279, top3_acc=0.6295 macro_f1=0.1508\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7508, top3_acc=0.6656 macro_f1=0.1733\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7639, top3_acc=0.6689 macro_f1=0.1868\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7541, top3_acc=0.6623 macro_f1=0.1917\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7541, top3_acc=0.6689 macro_f1=0.1942\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7869, top3_acc=0.6689 macro_f1=0.1905\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7672, top3_acc=0.6918 macro_f1=0.2414\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7869, top3_acc=0.6918 macro_f1=0.2468\n",
      "VAL: top1_acc=0.5180, top5_acc=0.7869, top3_acc=0.7049 macro_f1=0.2465\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7639, top3_acc=0.6820 macro_f1=0.2219\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7869, top3_acc=0.6951 macro_f1=0.2182\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7639, top3_acc=0.6951 macro_f1=0.2288\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7902, top3_acc=0.7016 macro_f1=0.2347\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7869, top3_acc=0.6885 macro_f1=0.2544\n",
      "VAL: top1_acc=0.4885, top5_acc=0.7803, top3_acc=0.6918 macro_f1=0.2625\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7803, top3_acc=0.6951 macro_f1=0.2314\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7738, top3_acc=0.6951 macro_f1=0.2712\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7770, top3_acc=0.6984 macro_f1=0.2477\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7770, top3_acc=0.7016 macro_f1=0.2735\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7803, top3_acc=0.6951 macro_f1=0.2662\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7869, top3_acc=0.7049 macro_f1=0.2671\n",
      "VAL: top1_acc=0.5279, top5_acc=0.7770, top3_acc=0.7016 macro_f1=0.2872\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7738, top3_acc=0.6787 macro_f1=0.2416\n",
      "Early stopping at epoch 135\n",
      "HID64_DO0.35_SEED1__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number TEST: top1_acc=0.4739, top5_acc=0.7516, top3_acc=0.6569 macro_f1=0.3013\n",
      "\n",
      "===== Training config: HID64_DO0.35_SEED2__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number =====\n",
      "VAL: top1_acc=0.3279, top5_acc=0.5115, top3_acc=0.4623 macro_f1=0.0701\n",
      "VAL: top1_acc=0.4262, top5_acc=0.6885, top3_acc=0.5869 macro_f1=0.1328\n",
      "VAL: top1_acc=0.4492, top5_acc=0.7148, top3_acc=0.6164 macro_f1=0.1468\n",
      "VAL: top1_acc=0.4689, top5_acc=0.7213, top3_acc=0.6492 macro_f1=0.1864\n",
      "VAL: top1_acc=0.4885, top5_acc=0.7443, top3_acc=0.6557 macro_f1=0.1899\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7410, top3_acc=0.6459 macro_f1=0.1820\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7541, top3_acc=0.6820 macro_f1=0.1977\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7672, top3_acc=0.6852 macro_f1=0.2182\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7738, top3_acc=0.7016 macro_f1=0.2273\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7770, top3_acc=0.7213 macro_f1=0.2294\n",
      "VAL: top1_acc=0.5180, top5_acc=0.7836, top3_acc=0.6951 macro_f1=0.2340\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7803, top3_acc=0.6885 macro_f1=0.2115\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7869, top3_acc=0.6984 macro_f1=0.2185\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7738, top3_acc=0.6754 macro_f1=0.2247\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7836, top3_acc=0.6951 macro_f1=0.2378\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7770, top3_acc=0.6951 macro_f1=0.2408\n",
      "VAL: top1_acc=0.5246, top5_acc=0.7869, top3_acc=0.6918 macro_f1=0.2523\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7836, top3_acc=0.7082 macro_f1=0.2238\n",
      "VAL: top1_acc=0.5213, top5_acc=0.7967, top3_acc=0.7115 macro_f1=0.2470\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7934, top3_acc=0.7213 macro_f1=0.2160\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7869, top3_acc=0.6984 macro_f1=0.2669\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7836, top3_acc=0.7115 macro_f1=0.2355\n",
      "VAL: top1_acc=0.5311, top5_acc=0.7869, top3_acc=0.7115 macro_f1=0.2734\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7869, top3_acc=0.7279 macro_f1=0.2452\n",
      "VAL: top1_acc=0.5279, top5_acc=0.8066, top3_acc=0.7115 macro_f1=0.2780\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7836, top3_acc=0.7115 macro_f1=0.2369\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7902, top3_acc=0.6852 macro_f1=0.2514\n",
      "VAL: top1_acc=0.5049, top5_acc=0.8131, top3_acc=0.7049 macro_f1=0.2401\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7902, top3_acc=0.6820 macro_f1=0.2304\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7705, top3_acc=0.6951 macro_f1=0.2359\n",
      "VAL: top1_acc=0.5180, top5_acc=0.7770, top3_acc=0.6984 macro_f1=0.2602\n",
      "VAL: top1_acc=0.5180, top5_acc=0.7934, top3_acc=0.7246 macro_f1=0.2541\n",
      "VAL: top1_acc=0.4787, top5_acc=0.7967, top3_acc=0.7082 macro_f1=0.2148\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7869, top3_acc=0.7115 macro_f1=0.2588\n",
      "VAL: top1_acc=0.5180, top5_acc=0.7738, top3_acc=0.7180 macro_f1=0.2713\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7967, top3_acc=0.7049 macro_f1=0.2238\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7705, top3_acc=0.7049 macro_f1=0.2300\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7869, top3_acc=0.7180 macro_f1=0.2470\n",
      "Early stopping at epoch 190\n",
      "HID64_DO0.35_SEED2__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number TEST: top1_acc=0.4641, top5_acc=0.7614, top3_acc=0.6601 macro_f1=0.3027\n",
      "\n",
      "===== Training config: HID64_DO0.35_SEED3__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number =====\n",
      "VAL: top1_acc=0.3082, top5_acc=0.4918, top3_acc=0.4426 macro_f1=0.0527\n",
      "VAL: top1_acc=0.4262, top5_acc=0.6689, top3_acc=0.5869 macro_f1=0.1492\n",
      "VAL: top1_acc=0.4590, top5_acc=0.6951, top3_acc=0.6131 macro_f1=0.1522\n",
      "VAL: top1_acc=0.4656, top5_acc=0.7344, top3_acc=0.6328 macro_f1=0.1575\n",
      "VAL: top1_acc=0.4590, top5_acc=0.7377, top3_acc=0.6328 macro_f1=0.1803\n",
      "VAL: top1_acc=0.4557, top5_acc=0.7377, top3_acc=0.6557 macro_f1=0.1600\n",
      "VAL: top1_acc=0.4721, top5_acc=0.7738, top3_acc=0.6623 macro_f1=0.1710\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7508, top3_acc=0.6426 macro_f1=0.1828\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7934, top3_acc=0.6852 macro_f1=0.2244\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7803, top3_acc=0.6689 macro_f1=0.2233\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7770, top3_acc=0.6951 macro_f1=0.2295\n",
      "VAL: top1_acc=0.5246, top5_acc=0.7934, top3_acc=0.7016 macro_f1=0.2626\n",
      "VAL: top1_acc=0.4885, top5_acc=0.7902, top3_acc=0.6885 macro_f1=0.2226\n",
      "VAL: top1_acc=0.5115, top5_acc=0.8000, top3_acc=0.6918 macro_f1=0.2521\n",
      "VAL: top1_acc=0.5213, top5_acc=0.7967, top3_acc=0.7016 macro_f1=0.2707\n",
      "VAL: top1_acc=0.4820, top5_acc=0.8066, top3_acc=0.6951 macro_f1=0.2100\n",
      "VAL: top1_acc=0.4885, top5_acc=0.8000, top3_acc=0.6852 macro_f1=0.2287\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7902, top3_acc=0.6885 macro_f1=0.2507\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7705, top3_acc=0.6787 macro_f1=0.2135\n",
      "VAL: top1_acc=0.5049, top5_acc=0.8033, top3_acc=0.6951 macro_f1=0.2508\n",
      "VAL: top1_acc=0.4984, top5_acc=0.8033, top3_acc=0.6918 macro_f1=0.2425\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7967, top3_acc=0.7049 macro_f1=0.2173\n",
      "VAL: top1_acc=0.5016, top5_acc=0.8033, top3_acc=0.7082 macro_f1=0.2399\n",
      "VAL: top1_acc=0.5246, top5_acc=0.8230, top3_acc=0.7016 macro_f1=0.2670\n",
      "VAL: top1_acc=0.4885, top5_acc=0.8033, top3_acc=0.7049 macro_f1=0.2369\n",
      "VAL: top1_acc=0.4689, top5_acc=0.7934, top3_acc=0.7115 macro_f1=0.2301\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7902, top3_acc=0.7115 macro_f1=0.2507\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7967, top3_acc=0.6951 macro_f1=0.2317\n",
      "VAL: top1_acc=0.4984, top5_acc=0.8000, top3_acc=0.6918 macro_f1=0.2238\n",
      "VAL: top1_acc=0.5115, top5_acc=0.8098, top3_acc=0.6951 macro_f1=0.2500\n",
      "VAL: top1_acc=0.4951, top5_acc=0.8295, top3_acc=0.7115 macro_f1=0.2299\n",
      "VAL: top1_acc=0.4918, top5_acc=0.8033, top3_acc=0.6951 macro_f1=0.2414\n",
      "VAL: top1_acc=0.5082, top5_acc=0.8000, top3_acc=0.7115 macro_f1=0.2463\n",
      "VAL: top1_acc=0.4951, top5_acc=0.8000, top3_acc=0.7213 macro_f1=0.2490\n",
      "VAL: top1_acc=0.4721, top5_acc=0.7705, top3_acc=0.6885 macro_f1=0.2397\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7803, top3_acc=0.7016 macro_f1=0.2700\n",
      "VAL: top1_acc=0.4820, top5_acc=0.8066, top3_acc=0.6951 macro_f1=0.2243\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7934, top3_acc=0.6918 macro_f1=0.2349\n",
      "VAL: top1_acc=0.4885, top5_acc=0.8033, top3_acc=0.7148 macro_f1=0.2302\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7934, top3_acc=0.7049 macro_f1=0.2245\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7902, top3_acc=0.6852 macro_f1=0.2322\n",
      "Early stopping at epoch 205\n",
      "HID64_DO0.35_SEED3__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number TEST: top1_acc=0.4673, top5_acc=0.7451, top3_acc=0.6667 macro_f1=0.2803\n",
      "\n",
      "===== Training config: HID64_DO0.35_SEED4__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number =====\n",
      "VAL: top1_acc=0.3213, top5_acc=0.5246, top3_acc=0.4492 macro_f1=0.0659\n",
      "VAL: top1_acc=0.4525, top5_acc=0.6951, top3_acc=0.5869 macro_f1=0.1697\n",
      "VAL: top1_acc=0.4525, top5_acc=0.7082, top3_acc=0.6098 macro_f1=0.1761\n",
      "VAL: top1_acc=0.4656, top5_acc=0.7213, top3_acc=0.6295 macro_f1=0.1902\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7639, top3_acc=0.6787 macro_f1=0.1808\n",
      "VAL: top1_acc=0.4885, top5_acc=0.7705, top3_acc=0.6689 macro_f1=0.1879\n",
      "VAL: top1_acc=0.4885, top5_acc=0.7672, top3_acc=0.6721 macro_f1=0.1919\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7508, top3_acc=0.6656 macro_f1=0.1910\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7869, top3_acc=0.6885 macro_f1=0.2071\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7934, top3_acc=0.6852 macro_f1=0.2084\n",
      "VAL: top1_acc=0.5344, top5_acc=0.7770, top3_acc=0.6820 macro_f1=0.2800\n",
      "VAL: top1_acc=0.5246, top5_acc=0.7738, top3_acc=0.7049 macro_f1=0.2383\n",
      "VAL: top1_acc=0.5213, top5_acc=0.7770, top3_acc=0.6984 macro_f1=0.2460\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7934, top3_acc=0.7016 macro_f1=0.2207\n",
      "VAL: top1_acc=0.4984, top5_acc=0.8033, top3_acc=0.6918 macro_f1=0.2225\n",
      "VAL: top1_acc=0.5344, top5_acc=0.7902, top3_acc=0.6918 macro_f1=0.2748\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7902, top3_acc=0.7016 macro_f1=0.2246\n",
      "VAL: top1_acc=0.5049, top5_acc=0.8066, top3_acc=0.6951 macro_f1=0.2353\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7934, top3_acc=0.7082 macro_f1=0.2531\n",
      "VAL: top1_acc=0.5148, top5_acc=0.8033, top3_acc=0.7279 macro_f1=0.2590\n",
      "VAL: top1_acc=0.5049, top5_acc=0.8131, top3_acc=0.7180 macro_f1=0.2209\n",
      "VAL: top1_acc=0.4951, top5_acc=0.8033, top3_acc=0.7180 macro_f1=0.2208\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7934, top3_acc=0.7246 macro_f1=0.2267\n",
      "VAL: top1_acc=0.4951, top5_acc=0.8000, top3_acc=0.6885 macro_f1=0.2036\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7869, top3_acc=0.7082 macro_f1=0.2300\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7869, top3_acc=0.6885 macro_f1=0.2609\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7902, top3_acc=0.7082 macro_f1=0.2229\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7934, top3_acc=0.6885 macro_f1=0.2526\n",
      "VAL: top1_acc=0.5148, top5_acc=0.8098, top3_acc=0.6984 macro_f1=0.2684\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7934, top3_acc=0.7049 macro_f1=0.2646\n",
      "VAL: top1_acc=0.4623, top5_acc=0.7967, top3_acc=0.6918 macro_f1=0.2303\n",
      "Early stopping at epoch 155\n",
      "HID64_DO0.35_SEED4__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number TEST: top1_acc=0.4477, top5_acc=0.7810, top3_acc=0.6765 macro_f1=0.2759\n",
      "\n",
      "===== Training config: HID64_DO0.35_SEED5__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number =====\n",
      "VAL: top1_acc=0.2689, top5_acc=0.4885, top3_acc=0.4197 macro_f1=0.0331\n",
      "VAL: top1_acc=0.4361, top5_acc=0.6689, top3_acc=0.5672 macro_f1=0.1376\n",
      "VAL: top1_acc=0.4590, top5_acc=0.6918, top3_acc=0.6328 macro_f1=0.1585\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7246, top3_acc=0.6525 macro_f1=0.1652\n",
      "VAL: top1_acc=0.4656, top5_acc=0.7246, top3_acc=0.6557 macro_f1=0.1772\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7213, top3_acc=0.6295 macro_f1=0.1834\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7541, top3_acc=0.6590 macro_f1=0.1953\n",
      "VAL: top1_acc=0.4885, top5_acc=0.7541, top3_acc=0.6623 macro_f1=0.1972\n",
      "VAL: top1_acc=0.4885, top5_acc=0.7672, top3_acc=0.6754 macro_f1=0.1977\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7770, top3_acc=0.6852 macro_f1=0.2076\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7803, top3_acc=0.7082 macro_f1=0.2095\n",
      "VAL: top1_acc=0.5344, top5_acc=0.8033, top3_acc=0.7148 macro_f1=0.2443\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7902, top3_acc=0.6885 macro_f1=0.2038\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7803, top3_acc=0.6984 macro_f1=0.2190\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7803, top3_acc=0.7016 macro_f1=0.2445\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7803, top3_acc=0.7082 macro_f1=0.2441\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7869, top3_acc=0.7115 macro_f1=0.2328\n",
      "VAL: top1_acc=0.4787, top5_acc=0.7803, top3_acc=0.7082 macro_f1=0.2119\n",
      "VAL: top1_acc=0.5180, top5_acc=0.8000, top3_acc=0.7279 macro_f1=0.2621\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7934, top3_acc=0.7246 macro_f1=0.2462\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7967, top3_acc=0.7115 macro_f1=0.2479\n",
      "VAL: top1_acc=0.5148, top5_acc=0.8000, top3_acc=0.7311 macro_f1=0.2481\n",
      "Early stopping at epoch 110\n",
      "HID64_DO0.35_SEED5__atomic_one_hot_cordinates_crystal_system_oms_porosity_space_group_number TEST: top1_acc=0.4673, top5_acc=0.7516, top3_acc=0.6732 macro_f1=0.2467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calcolo dinamico della dimensione delle extra\n",
    "extras_dim = compute_extras_dim(dataset[0], selected_extras)\n",
    "\n",
    "# Classi\n",
    "Y_size = max([torch.argmax(d[\"metal_salts\"]).item() for d in dataset])\n",
    "num_classes = Y_size + 1\n",
    "\n",
    "number_of_runs = [1,2,3,4,5]\n",
    "hidden_dim = 64\n",
    "dropout = 0.35\n",
    "\n",
    "results = []\n",
    "suffix = extras_suffix(selected_extras)\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__{suffix}\"\n",
    "    print(f\"\\n===== Training config: {config_name} =====\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = MetalSaltGNN_Ablation(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True,\n",
    "        selected_extras=selected_extras,\n",
    "        extras_dim=extras_dim\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    checkpoint_name = f\"tmp2/Metal_salts_{config_name}.pt\"\n",
    "\n",
    "    best_metric = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 50\n",
    "    eval_every = 5\n",
    "\n",
    "    for epoch in range(1, 1001):\n",
    "        _ = train_one_epoch(model, train_loader, criterion, optimizer, device, \"metal_salts\")\n",
    "        if epoch % eval_every == 0:\n",
    "            res = evaluate(model, val_loader, device, \"metal_salts\")\n",
    "            print(f\"VAL: top1_acc={res['top1_acc']:.4f}, top5_acc={res['top5_acc']:.4f}, top3_acc={res['top3_acc']:.4f} macro_f1={res['macro_f1']:.4f}\")\n",
    "\n",
    "            # Early stopping su top5, come nel tuo codice\n",
    "            if res[\"top5_acc\"] > best_metric:\n",
    "                best_metric = res[\"top5_acc\"]\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), checkpoint_name)\n",
    "            else:\n",
    "                epochs_no_improve += eval_every\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # Valutazione test con il best checkpoint\n",
    "    model.load_state_dict(torch.load(checkpoint_name, map_location=device))\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "    results.append({**res_test, 'config': config_name})\n",
    "    print(f\"{config_name} TEST: top1_acc={res_test['top1_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f} macro_f1={res_test['macro_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f953de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac8da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d617444",
   "metadata": {},
   "source": [
    "# evalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ee7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Media ± Std sulle run ====\n",
      "\n",
      "top1_acc: 0.4641 ± 0.0088\n",
      "top3_acc: 0.6667 ± 0.0075\n",
      "top5_acc: 0.7582 ± 0.0126\n",
      "top10_acc: 0.8837 ± 0.0087\n",
      "macro_f1: 0.2814 ± 0.0204\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__{suffix}\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    model = MetalSaltGNN_Ablation(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True,\n",
    "        selected_extras=selected_extras,\n",
    "        extras_dim=extras_dim\n",
    "    ).to(device)\n",
    "\n",
    "    checkpoint_name = f\"tmp2/Metal_salts_{config_name}.pt\"\n",
    "    checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'top1_acc':  res_test['top1_acc'],\n",
    "        'top3_acc':  res_test['top3_acc'],\n",
    "        'top5_acc':  res_test['top5_acc'],\n",
    "        'top10_acc': res_test['top10_acc'],\n",
    "        'macro_f1':  res_test['macro_f1'],\n",
    "    })\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "# results è la tua lista di dict\n",
    "metrics = [\"top1_acc\",\"top3_acc\",\"top5_acc\",\"top10_acc\",\"macro_f1\"]\n",
    "\n",
    "print(\"==== Media ± Std sulle run ====\\n\")\n",
    "for metric in metrics:\n",
    "    values = [r[metric] for r in results]\n",
    "    mean = np.mean(values)\n",
    "    std  = np.std(values)\n",
    "    print(f\"{metric}: {mean:.4f} ± {std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230c529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2d298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5483cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991cdbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169c3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7be2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool,GINConv\n",
    "\n",
    "\n",
    "# ==================== Model ====================\n",
    "\n",
    "class MetalSaltGNN_v2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in_dim=4,     # da x.shape[1]\n",
    "        edge_in_dim=1,     # da edge_attr.shape[1]\n",
    "        lattice_in_dim=9,  # 3x3 flatten\n",
    "        hidden_dim=128,\n",
    "        num_classes=10,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=0.2,\n",
    "        use_batchnorm=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # --- Edge encoder (per GINE)\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # --- GINE layers\n",
    "        self.gnn_layers = nn.ModuleList()\n",
    "        self.gnn_bns = nn.ModuleList() if use_batchnorm else None\n",
    "        for i in range(num_gnn_layers):\n",
    "            in_dim = node_in_dim if i == 0 else hidden_dim\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.gnn_layers.append(GINEConv(mlp, edge_dim=hidden_dim))\n",
    "            if use_batchnorm:\n",
    "                self.gnn_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # --- Lattice encoder\n",
    "        lattice_layers = []\n",
    "        in_dim = lattice_in_dim\n",
    "        for _ in range(max(1, num_lattice_layers - 1)):\n",
    "            lattice_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                lattice_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            in_dim = hidden_dim\n",
    "        lattice_layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.lattice_encoder = nn.Sequential(*lattice_layers)\n",
    "\n",
    "        # --- Final MLP head\n",
    "        # Extra graph-level features\n",
    "        extra_dim = 120 + 231 + 7 + 1 + 8 + 96\n",
    "        final_in = hidden_dim * 2 + extra_dim\n",
    "\n",
    "        mlp_layers = []\n",
    "        in_dim = final_in\n",
    "        for _ in range(max(1, num_mlp_layers - 1)):\n",
    "            mlp_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                mlp_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            mlp_layers.append(nn.Dropout(p=dropout))\n",
    "            in_dim = hidden_dim\n",
    "        mlp_layers.append(nn.Linear(in_dim, num_classes))\n",
    "        self.final_mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        lattice = data.lattice\n",
    "\n",
    "        # Per-graph extras\n",
    "        atomic_oh = data.atomic_one_hot.view(-1, 120)\n",
    "        sg_oh = data.space_group_number.view(-1, 231)\n",
    "        cs_oh = data.crystal_system.view(-1, 7)\n",
    "        oms = data.oms.view(-1, 1)\n",
    "        porosity = data.porosity.view(-1, 8)\n",
    "        coords = data.cordinates.view(-1, 96)\n",
    "\n",
    "        # Encode edges\n",
    "        e = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # GNN layers\n",
    "        for i, conv in enumerate(self.gnn_layers):\n",
    "            x = conv(x, edge_index, e)\n",
    "            x = F.relu(x)\n",
    "            if self.use_batchnorm:\n",
    "                x = self.gnn_bns[i](x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Global pooling\n",
    "        x_pool = global_mean_pool(x, batch)\n",
    "\n",
    "        # Lattice encoding\n",
    "        lattice = lattice.view(-1, 9)\n",
    "        lattice_feat = self.lattice_encoder(lattice)\n",
    "\n",
    "        # Concatenate everything\n",
    "        extras = torch.cat([atomic_oh, sg_oh, cs_oh, oms, porosity, coords], dim=1)\n",
    "        final_in = torch.cat([x_pool, lattice_feat, extras], dim=1)\n",
    "\n",
    "        out = self.final_mlp(final_in)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ==================== Train / Eval helpers ====================\n",
    "def train(model, loader, criterion, optimizer, device, target_name):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        # target expected one-hot per-graph -> class indices\n",
    "        target = torch.argmax(data[target_name], dim=1).long()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, target_name):\n",
    "    model.eval()\n",
    "    correct = {1: 0, 3: 0, 5: 0, 10: 0}\n",
    "    total = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        labels = torch.argmax(data[target_name], dim=1).long()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Top-k accuracy\n",
    "        _, pred = logits.topk(10, dim=1)\n",
    "        for k in correct.keys():\n",
    "            correct[k] += (pred[:, :k] == labels.view(-1, 1)).any(dim=1).sum().item()\n",
    "\n",
    "        # Per F1: usiamo solo la predizione top1\n",
    "        top1_preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(top1_preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    # Concatena\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    macro_f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average=\"macro\")\n",
    "\n",
    "    results = {f\"top{k}_acc\": correct[k] / max(1, total) for k in correct}\n",
    "    results[\"macro_f1\"] = macro_f1\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_in_dim = dataset[0].x.shape[1]\n",
    "edge_in_dim = dataset[0].edge_attr.shape[1]\n",
    "lattice_in_dim = 9\n",
    "\n",
    "number_of_runs = [1,2,3]  # \n",
    "\n",
    "hidden_dim = 64\n",
    "dropout = 0.35\n",
    "\n",
    "\n",
    "Y_size = max([torch.argmax(d[\"metal_salts\"]).item() for d in dataset])\n",
    "num_classes = Y_size + 1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a12f7b",
   "metadata": {},
   "source": [
    "### 3) Train the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__X_edgeAttr_lattice_oms_AtomicNumber_structsym\"\n",
    "    print(f\"\\n===== Training config: {config_name} =====\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    # ==================== Model ====================\n",
    "    model = MetalSaltGNN_v2(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes, \n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=0.0001)\n",
    "    checkpoint_name = f\"tmp2/Metal_salts_{config_name}.pt\"\n",
    "    best_metric = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 50\n",
    "    eval_every = 5\n",
    "\n",
    "    for epoch in range(1, 1001):\n",
    "        train(model, train_loader, criterion, optimizer, device, \"metal_salts\")\n",
    "        if epoch % eval_every == 0:\n",
    "            res = evaluate(model, val_loader, device, \"metal_salts\")\n",
    "            print(f\"VAL: top1_acc={res['top1_acc']:.4f}, top5_acc={res['top5_acc']:.4f}, top3_acc={res['top3_acc']:.4f} macro_f1={res['macro_f1']:.4f}\")\n",
    "            \n",
    "            if res[\"top5_acc\"] > best_metric:\n",
    "                best_metric = res[\"top5_acc\"]\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), checkpoint_name)\n",
    "            else:\n",
    "                epochs_no_improve += eval_every\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_name))\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "    results.append({**res_test, 'config': config_name})\n",
    "    print(f\"{config_name} TEST: top1_acc={res_test['top1_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f} macro_f1={res_test['macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25722051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db04f4",
   "metadata": {},
   "source": [
    "### 4) Load and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22757017",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__X_edgeAttr_lattice_oms_AtomicNumber_structsym\"\n",
    "    print(f\"\\n===== Evaluating config: {config_name} =====\")\n",
    "    \n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    model = MetalSaltGNN_v2(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes, \n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint_name = f\"tmp2/Metal_salts_{config_name}.pt\"\n",
    "    # Carica best model e valuta su test\n",
    "    checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'top1_acc': res_test['top1_acc'],\n",
    "        'top10_acc': res_test['top10_acc'],\n",
    "        'top5_acc': res_test['top5_acc'],\n",
    "        'top3_acc': res_test['top3_acc'],\n",
    "        'macro_f1': res_test['macro_f1']\n",
    "    })\n",
    "    print(f\"{config_name} TEST: top10_acc={res_test['top10_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f}, macro_f1={res_test['macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f6466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bde3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cc751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95f257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6580e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "set_seed(seed=42)\n",
    "\n",
    "data_in = load_pyg_obj(path_to_mdb=\"../../data/mof_syncondition_data/\")\n",
    "dataset = fix_target_shapes(data_in, \"metal_salts\")\n",
    "dataset = remove_unused_onehot_columns(dataset, \"metal_salts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d990e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf292fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baaf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = torch.nn.functional.one_hot(torch.tensor(idx), num_classes=len(unique_atomic_numbers)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed39174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e476ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7bf471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f2a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4375f232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884932c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7852b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa08e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55aa79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba51402",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3fa48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(atom_num,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71524153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[0,8,0,0,0,..,32,0,4,0,0,0,0,0,0] # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc6622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.data import atomic_numbers\n",
    "\n",
    "atomic_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aa486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc224fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a, _ = np.unique(filter_metals(d.x.numpy()[:,0].astype(int)), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f77c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metals(d.x.numpy()[:,0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofstructure.mofdeconstructor import transition_metals\n",
    "\n",
    "\n",
    "from ase.data import atomic_numbers\n",
    "\n",
    "len(transition_metals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.data import atomic_numbers\n",
    "\n",
    "atomic_numbers\n",
    "\n",
    "\n",
    "[atomic_numbers[i] for i in transition_metals()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86a05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18032669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "unique_atomic_numbers = np.unique(atomic_numb)\n",
    "atomic_to_idx = {num: idx for idx, num in enumerate(unique_atomic_numbers)}\n",
    "\n",
    "for data in dataset:\n",
    "    node_features = data.x.numpy()\n",
    "    atomic_number = filter_metals(node_features[:, 0].astype(int))\n",
    "    atomic_number = np.unique(atomic_number)[0]\n",
    "    idx = atomic_to_idx[atomic_number]\n",
    "    one_hot = torch.nn.functional.one_hot(torch.tensor(idx), num_classes=len(unique_atomic_numbers)).float()\n",
    "    data.atomic_one_hot = one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.data import chemical_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cd249",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_symbols[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d770a8",
   "metadata": {},
   "source": [
    "# real word experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b92e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mofstructure import structure, mofdeconstructor\n",
    "from mofstructure.filetyper import load_iupac_names\n",
    "from fairmofsyncondition.read_write import cheminfo2iupac, coords_library, filetyper\n",
    "from ase.data import atomic_numbers\n",
    "from ase.io import read\n",
    "import torch\n",
    "\n",
    "\n",
    "inchi_corrector = {\n",
    "    \"FDTQOZYHNDMJCM-UHFFFAOYSA-N\":\"benzene-1,4-dicarboxylic acid\"\n",
    "}\n",
    "def get_ligand_iupacname(ligand_inchi):\n",
    "    print(ligand_inchi)\n",
    "    name = load_iupac_names().get(ligand_inchi, None)\n",
    "    if name is None:\n",
    "        pubchem = cheminfo2iupac.pubchem_to_inchikey(ligand_inchi, name='inchikey')\n",
    "        if pubchem is None:\n",
    "            name = inchi_corrector.get(ligand_inchi, ligand_inchi)\n",
    "        else:\n",
    "            pubchem.get('iupac_name', ligand_inchi)\n",
    "    return name\n",
    "\n",
    "\n",
    "def load_system(filename):\n",
    "    \"\"\"\n",
    "    A function to extract\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    os.makedirs('LigandsXYZ', exist_ok=True)\n",
    "    ase_data = read(filename)\n",
    "    structure_data = structure.MOFstructure(ase_atoms=ase_data)\n",
    "    _, ligands = structure_data.get_ligands()\n",
    "\n",
    "    inchikeys = [ligand.info.get('inchikey') for ligand in ligands]\n",
    "    for inchi, ligand in zip(inchikeys, ligands):\n",
    "        ligand.write(f'LigandsXYZ/{inchi}.xyz')\n",
    "    ligands_names = [get_ligand_iupacname(i) for i in inchikeys]\n",
    "    general = structure_data.get_oms()\n",
    "    oms = general.get('has_oms')\n",
    "    metal_symbols = general.get('metals')\n",
    "    metals_atomic_number = [atomic_numbers[i] for i in metal_symbols]\n",
    "    torch_data = coords_library.ase_to_pytorch_geometric(ase_data)\n",
    "    oms = torch.tensor([1 if  oms else 0], dtype=torch.int16)\n",
    "    torch_data.oms = oms\n",
    "    data['general'] = general\n",
    "    return torch_data, metals_atomic_number, inchikeys, ligands_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b40a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"EDUSIF.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"Zn2C43N6H29O8.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"ZnC5HO5.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17791fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofstructure.structure import MOFstructure\n",
    "convert_metals = {j:i for i,j in enumerate(mofdeconstructor.transition_metals()[1:])}\n",
    "\n",
    "\n",
    "# Parte 1: atomic one-hot\n",
    "# =======================\n",
    "node_features = d.x.numpy()\n",
    "atom_num = node_features[:, 0].astype(int)\n",
    "a, b = np.unique(atom_num, return_counts=True)\n",
    "emb = torch.zeros(120)\n",
    "for aa, bb in zip(a, b):\n",
    "    emb[aa] = bb\n",
    "d.atomic_one_hot = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 2: struttura ASE\n",
    "# =======================\n",
    "ase_atoms = pytorch_geometric_to_ase(d)\n",
    "stru = MOFstructure(ase_atoms)\n",
    "pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "\n",
    "# =======================\n",
    "# Parte 3: OMS\n",
    "# =======================\n",
    "emb = torch.zeros(96)\n",
    "tmp_dict = dict()\n",
    "for i in stru.get_oms()[\"metal_info\"]:\n",
    "    cord = i[\"coordination_number\"]\n",
    "    metal = i[\"metal\"]\n",
    "\n",
    "    if metal in tmp_dict:\n",
    "        if cord > tmp_dict[metal]:\n",
    "            tmp_dict[metal] = cord\n",
    "    else:\n",
    "        tmp_dict[metal] = cord\n",
    "\n",
    "for i, j in tmp_dict.items():\n",
    "    emb[convert_metals[i]] = j\n",
    "d.cordinates = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 4: spazio e sistema cristallino\n",
    "# =======================\n",
    "sga = SpacegroupAnalyzer(pymat)\n",
    "space_group_number = sga.get_space_group_number()\n",
    "emb = torch.zeros(231)\n",
    "emb[space_group_number] = 1\n",
    "d.space_group_number = emb\n",
    "\n",
    "get_crystal_system = sga.get_crystal_system()\n",
    "emb = torch.zeros(7)\n",
    "emb[convert_struct[get_crystal_system]] = 1\n",
    "d.crystal_system = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 5: altri attributi\n",
    "# =======================\n",
    "###\n",
    "to get oms\n",
    "stru.get_oms()[\"has_oms\"]\n",
    "\n",
    "d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "por = stru.get_porosity()\n",
    "por = list(por.values())\n",
    "d.porosity = torch.tensor(por)\n",
    "\n",
    "d.modified_scherrer = None\n",
    "d.microstrain = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(d.to(device))\n",
    "prx = \"Zn\"\n",
    "\n",
    "c = 0\n",
    "for i in pred.argsort()[0]:\n",
    "    a = filetyper.category_names()[\"metal_salts\"][i.item()]\n",
    "    \n",
    "    if a[:2] == prx:\n",
    "        print(a)\n",
    "        c = c +1 \n",
    "        \n",
    "    if c == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e96d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ad21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairmof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
