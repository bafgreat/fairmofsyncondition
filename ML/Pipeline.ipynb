{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda9bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/miniconda3/envs/fairmof/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_pyg_obj\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import fix_target_shapes,remove_unused_onehot_columns,set_seed,filter_metals\n",
    "from mofstructure import mofdeconstructor\n",
    "\n",
    "from fairmofsyncondition.read_write.coords_library import pytorch_geometric_to_ase\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "\n",
    "convert_struct = {'cubic':0, 'hexagonal':1, 'monoclinic':2, 'orthorhombic':3, 'tetragonal':4,'triclinic':5, 'trigonal':6}\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a212130",
   "metadata": {},
   "source": [
    "# GNN for Metal Salt Prediction\n",
    "\n",
    "This code implements a **Graph Neural Network (GNN)** to predict metal salts, using:\n",
    "- **Node Features**  \n",
    "- **Edge Features**  \n",
    "- **Lattice**   \n",
    "- **Oms**\n",
    "- **Atomic number**\n",
    "---\n",
    "\n",
    "## Code Structure\n",
    "\n",
    "1. **Load the Data**  \n",
    "   Import and prepare the dataset for use in the model.\n",
    "\n",
    "2. **Define the GNN Model**  \n",
    "   Define the neural network architecture (layers, activation functions, etc.).\n",
    "\n",
    "3. **Train the Model**  \n",
    "   - Train the model on the dataset.  \n",
    "   - Save the trained GNN weights into the `tmp/` folder.  \n",
    "\n",
    "   ⚠️ **Note**:  \n",
    "   If you only want to **test the model** without re-training, you can **skip this section** and avoid running the training step.\n",
    "\n",
    "4. **Load and Evaluate the Model**  \n",
    "   - Load the trained model weights.  \n",
    "   - Evaluate the model performance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afb0dd",
   "metadata": {},
   "source": [
    "### 1) Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d29a2",
   "metadata": {},
   "source": [
    "\n",
    "### to get oms\n",
    "### stru.get_oms()[\"has_oms\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b02499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofstructure.structure import MOFstructure\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "convert_metals = {j:i for i,j in enumerate(mofdeconstructor.transition_metals()[1:])}\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362efd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_in = load_pyg_obj(path_to_mdb=\"../../data/mof_syncondition_data/\")\n",
    "dataset = fix_target_shapes(data_in, \"metal_salts\")\n",
    "#dataset1 = remove_unused_onehot_columns(dataset, \"metal_salts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ac073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b55568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336d635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8fe77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731f52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17366789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed dataset...\n"
     ]
    }
   ],
   "source": [
    "bad = []\n",
    "good = []\n",
    "\n",
    "if os.path.exists(\"../../dataset_cleen_all_info_test2.pt\"):\n",
    "    print(\"Loading precomputed dataset...\")\n",
    "    dataset = torch.load(\"../../dataset_cleen_all_info_test2.pt\")\n",
    "else:\n",
    "    print(\"Computing dataset with all info...\")\n",
    "    for d in tqdm(dataset):\n",
    "        try:\n",
    "            # =======================\n",
    "            # Parte 1: atomic one-hot\n",
    "            # =======================\n",
    "            node_features = d.x.numpy()\n",
    "            atom_num = node_features[:, 0].astype(int)\n",
    "            a, b = np.unique(atom_num, return_counts=True)\n",
    "            emb = torch.zeros(120)\n",
    "            for aa, bb in zip(a, b):\n",
    "                emb[aa] = bb\n",
    "            d.atomic_one_hot = emb\n",
    "            \n",
    "            # =======================\n",
    "            # Parte 2: struttura ASE\n",
    "            # =======================\n",
    "            ase_atoms = pytorch_geometric_to_ase(d)\n",
    "            stru = MOFstructure(ase_atoms)\n",
    "            pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "            \n",
    "            # =======================\n",
    "            # Parte 3: OMS\n",
    "            # =======================\n",
    "            emb = torch.zeros(96)\n",
    "            tmp_dict = dict()\n",
    "            for i in stru.get_oms()[\"metal_info\"]:\n",
    "                cord = i[\"coordination_number\"]\n",
    "                metal = i[\"metal\"]\n",
    "\n",
    "                if metal in tmp_dict:\n",
    "                    if cord > tmp_dict[metal]:\n",
    "                        tmp_dict[metal] = cord\n",
    "                else:\n",
    "                    tmp_dict[metal] = cord\n",
    "\n",
    "            for i, j in tmp_dict.items():\n",
    "                emb[convert_metals[i]] = j\n",
    "            d.cordinates = emb\n",
    "            \n",
    "            # =======================\n",
    "            # Parte 4: spazio e sistema cristallino\n",
    "            # =======================\n",
    "            sga = SpacegroupAnalyzer(pymat)\n",
    "            space_group_number = sga.get_space_group_number()\n",
    "            emb = torch.zeros(231)\n",
    "            emb[space_group_number] = 1\n",
    "            d.space_group_number = emb\n",
    "\n",
    "            get_crystal_system = sga.get_crystal_system()\n",
    "            emb = torch.zeros(7)\n",
    "            emb[convert_struct[get_crystal_system]] = 1\n",
    "            d.crystal_system = emb\n",
    "            # =======================\n",
    "            # Parte 5: altri attributi\n",
    "            # =======================\n",
    "            d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "            ###################### no porosity is too long to compute\n",
    "            #por = stru.get_porosity()\n",
    "            #por = list(por.values())\n",
    "            #d.porosity = torch.tensor(por)\n",
    "\n",
    "            d.modified_scherrer = None\n",
    "            d.microstrain = None\n",
    "\n",
    "            # Se arrivo qui senza eccezioni → struttura buona\n",
    "            good.append(d)\n",
    "        except Exception:\n",
    "            bad.append(d)\n",
    "            continue\n",
    "    torch.save(good, \"../../dataset_cleen_all_info_test2.pt\")   # salva lista di Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151c763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ec87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are classes 122 3054\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ==================== Utils & setup ====================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random, os\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Filtra classi rare (come nel tuo codice)\n",
    "Y = [d.metal_salts.argmax(dim=1).item() for d in dataset]\n",
    "a,b = np.unique(Y, return_counts=True)\n",
    "conv_y = {i:j for i,j in zip(a,b)}\n",
    "good = [d for d in dataset if conv_y[d.metal_salts.argmax(dim=1).item()] > 5]\n",
    "dataset = good\n",
    "\n",
    "print(\"There are classes\", len(np.unique([d.metal_salts.argmax(dim=1).item() for d in dataset])), len(dataset))\n",
    "\n",
    "# Split & loaders\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=128)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=128)\n",
    "\n",
    "# ==================== NEW: ablation helpers ====================\n",
    "\n",
    "# 1) Getter per ciascuna feature extra (sempre reshaped a [B, D])\n",
    "#    Aggiungi qui dentro eventuali nuove feature future.\n",
    "\n",
    "def _reshape_feat(tensor, d):\n",
    "    # Se è Batch (ha num_graphs)\n",
    "    if hasattr(d, \"num_graphs\"):\n",
    "        return tensor.view(d.num_graphs, -1)\n",
    "    else:  # è un singolo Data\n",
    "        return tensor.view(1, -1)\n",
    "\n",
    "EXTRA_GETTERS = {\n",
    "    \"atomic_one_hot\":      lambda d: _reshape_feat(d.atomic_one_hot, d),\n",
    "    \"space_group_number\":  lambda d: _reshape_feat(d.space_group_number, d),\n",
    "    \"crystal_system\":      lambda d: _reshape_feat(d.crystal_system, d),\n",
    "    \"oms\":                 lambda d: _reshape_feat(d.oms, d),\n",
    "    \"cordinates\":          lambda d: _reshape_feat(d.cordinates, d),\n",
    "}\n",
    "def compute_extras_dim(sample_data, selected_extras):\n",
    "    dim = 0\n",
    "    for name in selected_extras:\n",
    "        if name not in EXTRA_GETTERS:\n",
    "            raise ValueError(f\"Feature extra sconosciuta: {name}\")\n",
    "        dim += EXTRA_GETTERS[name](sample_data).shape[1]\n",
    "    return dim\n",
    "\n",
    "def build_extras_tensor(data, selected_extras):\n",
    "    if not selected_extras:\n",
    "        return None\n",
    "    parts = [EXTRA_GETTERS[name](data) for name in selected_extras]\n",
    "    return torch.cat(parts, dim=1)\n",
    "\n",
    "def extras_suffix(selected_extras):\n",
    "    if not selected_extras:\n",
    "        return \"no_extras\"\n",
    "    return \"_\".join(selected_extras)\n",
    "\n",
    "# ==================== Model ====================\n",
    "\n",
    "class MetalSaltGNN_Ablation(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in_dim,\n",
    "        edge_in_dim,\n",
    "        lattice_in_dim=9,\n",
    "        hidden_dim=128,\n",
    "        num_classes=10,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=0.2,\n",
    "        use_batchnorm=True,\n",
    "        selected_extras=None,      # NEW: lista di nomi feature extra\n",
    "        extras_dim=0               # NEW: dimensione totale delle extra\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.dropout = dropout\n",
    "        self.selected_extras = selected_extras or []\n",
    "        self.extras_dim = extras_dim\n",
    "\n",
    "        # --- Edge encoder (per GINE)\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # --- GINE layers\n",
    "        self.gnn_layers = nn.ModuleList()\n",
    "        self.gnn_bns = nn.ModuleList() if use_batchnorm else None\n",
    "        for i in range(num_gnn_layers):\n",
    "            in_dim = node_in_dim if i == 0 else hidden_dim\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.gnn_layers.append(GINEConv(mlp, edge_dim=hidden_dim))\n",
    "            if use_batchnorm:\n",
    "                self.gnn_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # --- Lattice encoder\n",
    "        lattice_layers = []\n",
    "        in_dim = lattice_in_dim\n",
    "        for _ in range(max(1, num_lattice_layers - 1)):\n",
    "            lattice_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                lattice_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            in_dim = hidden_dim\n",
    "        lattice_layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.lattice_encoder = nn.Sequential(*lattice_layers)\n",
    "\n",
    "        # --- Final MLP head\n",
    "        final_in = hidden_dim * 2 + self.extras_dim  # graph pooled + lattice + extras\n",
    "        mlp_layers = []\n",
    "        in_dim = final_in\n",
    "        for _ in range(max(1, num_mlp_layers - 1)):\n",
    "            mlp_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                mlp_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            mlp_layers.append(nn.Dropout(p=dropout))\n",
    "            in_dim = hidden_dim\n",
    "        mlp_layers.append(nn.Linear(in_dim, num_classes))\n",
    "        self.final_mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # Encode edges\n",
    "        e = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # GNN layers\n",
    "        for i, conv in enumerate(self.gnn_layers):\n",
    "            x = conv(x, edge_index, e)\n",
    "            x = F.relu(x)\n",
    "            if self.use_batchnorm:\n",
    "                x = self.gnn_bns[i](x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Global pooling\n",
    "        x_pool = global_mean_pool(x, batch)\n",
    "\n",
    "        # Lattice encoding (sempre usato)\n",
    "        lattice = data.lattice.view(-1, 9)\n",
    "        lattice_feat = self.lattice_encoder(lattice)\n",
    "\n",
    "        # Extras (abilitate in base alla lista)\n",
    "        extras = build_extras_tensor(data, self.selected_extras)\n",
    "        if extras is not None:\n",
    "            final_in = torch.cat([x_pool, lattice_feat, extras], dim=1)\n",
    "        else:\n",
    "            final_in = torch.cat([x_pool, lattice_feat], dim=1)\n",
    "\n",
    "        out = self.final_mlp(final_in)\n",
    "        return out\n",
    "\n",
    "# ==================== Train / Eval helpers ====================\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, target_name):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        target = torch.argmax(data[target_name], dim=1).long()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, target_name):\n",
    "    model.eval()\n",
    "    correct = {1: 0, 3: 0, 5: 0, 10: 0}\n",
    "    total = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        labels = torch.argmax(data[target_name], dim=1).long()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        _, pred = logits.topk(10, dim=1)\n",
    "        for k in correct.keys():\n",
    "            correct[k] += (pred[:, :k] == labels.view(-1, 1)).any(dim=1).sum().item()\n",
    "\n",
    "        top1_preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(top1_preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    macro_f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average=\"macro\")\n",
    "\n",
    "    results = {f\"top{k}_acc\": correct[k] / max(1, total) for k in correct}\n",
    "    results[\"macro_f1\"] = macro_f1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b26659",
   "metadata": {},
   "source": [
    "### 2) Define the GNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59c9e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atomic_one_hot', 'cordinates', 'oms', 'space_group_number']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==================== Run ablation ====================\n",
    "\n",
    "node_in_dim = dataset[0].x.shape[1]\n",
    "edge_in_dim = dataset[0].edge_attr.shape[1]\n",
    "lattice_in_dim = 9\n",
    "\n",
    "# Scegli qui le extra da usare nell’ablation:\n",
    "# Esempio richiesto: [\"oms\", \"atomic_one_hot\"]\n",
    "\n",
    "EXTRA_GETTERS = {\n",
    "    \"atomic_one_hot\":      lambda d: _reshape_feat(d.atomic_one_hot, d),\n",
    "    \"space_group_number\":  lambda d: _reshape_feat(d.space_group_number, d),\n",
    "    \"crystal_system\":      lambda d: _reshape_feat(d.crystal_system, d),\n",
    "    \"oms\":                 lambda d: _reshape_feat(d.oms, d),\n",
    "    \"cordinates\":          lambda d: _reshape_feat(d.cordinates, d),\n",
    "}\n",
    "\n",
    "selected_extras = []\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\"]\n",
    "selected_extras = [\"cordinates\"]\n",
    "selected_extras = [\"crystal_system\"]\n",
    "selected_extras = [\"oms\"]\n",
    "selected_extras = [\"space_group_number\"]\n",
    "\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\",\"cordinates\"]\n",
    "selected_extras = [\"atomic_one_hot\", \"crystal_system\"]\n",
    "selected_extras = [\"atomic_one_hot\", \"oms\"]\n",
    "selected_extras = [\"atomic_one_hot\", \"space_group_number\"]\n",
    "\n",
    "\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\", \"oms\", \"cordinates\"]\n",
    "selected_extras = [\"atomic_one_hot\", \"oms\", \"crystal_system\"]\n",
    "selected_extras = [\"atomic_one_hot\", \"oms\", \"space_group_number\"]\n",
    "\n",
    "\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\", \"oms\", \"cordinates\", \"crystal_system\"]\n",
    "selected_extras = [\"atomic_one_hot\", \"oms\", \"cordinates\", \"space_group_number\"]\n",
    "selected_extras = [\"atomic_one_hot\", \"cordinates\",\"crystal_system\", \"oms\",\"space_group_number\"]\n",
    "\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\", \"cordinates\", \"oms\",\"space_group_number\"]\n",
    "# imoprtant: for saving\n",
    "selected_extras = np.sort(selected_extras).tolist()\n",
    "selected_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932254da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dinamico della dimensione delle extra\n",
    "extras_dim = compute_extras_dim(dataset[0], selected_extras)\n",
    "\n",
    "# Classi\n",
    "Y_size = max([torch.argmax(d[\"metal_salts\"]).item() for d in dataset])\n",
    "num_classes = Y_size + 1\n",
    "\n",
    "number_of_runs = [1,2,3,4,5]\n",
    "hidden_dim = 64\n",
    "dropout = 0.35\n",
    "\n",
    "results = []\n",
    "suffix = extras_suffix(selected_extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24df511f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 448)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes,extras_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be2841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__{suffix}\"\n",
    "    print(f\"\\n===== Training config: {config_name} =====\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = MetalSaltGNN_Ablation(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True,\n",
    "        selected_extras=selected_extras,\n",
    "        extras_dim=extras_dim\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    checkpoint_name = f\"trained_models/Metal_salts_{config_name}_tmp_test.pt\"\n",
    "\n",
    "    best_metric = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 50\n",
    "    eval_every = 1\n",
    "\n",
    "    for epoch in range(1, 1001):\n",
    "        _ = train_one_epoch(model, train_loader, criterion, optimizer, device, \"metal_salts\")\n",
    "        if epoch % eval_every == 0:\n",
    "            res = evaluate(model, val_loader, device, \"metal_salts\")\n",
    "            print(f\"VAL: top1_acc={res['top1_acc']:.4f}, top5_acc={res['top5_acc']:.4f}, top3_acc={res['top3_acc']:.4f} macro_f1={res['macro_f1']:.4f}\")\n",
    "\n",
    "            # Early stopping su top5, come nel tuo codice\n",
    "            if res[\"top5_acc\"] > best_metric:\n",
    "                best_metric = res[\"top5_acc\"]\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), checkpoint_name)\n",
    "            else:\n",
    "                epochs_no_improve += eval_every\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # Valutazione test con il best checkpoint\n",
    "    model.load_state_dict(torch.load(checkpoint_name, map_location=device))\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "    results.append({**res_test, 'config': config_name})\n",
    "    print(f\"{config_name} TEST: top1_acc={res_test['top1_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f} macro_f1={res_test['macro_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d617444",
   "metadata": {},
   "source": [
    "# evalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ee7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Media ± Std sulle run ====\n",
      "\n",
      "top1_acc: 0.4575 ± 0.0000\n",
      "top3_acc: 0.6503 ± 0.0000\n",
      "top5_acc: 0.7484 ± 0.0000\n",
      "top10_acc: 0.8889 ± 0.0000\n",
      "macro_f1: 0.2952 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for seed in number_of_runs[0:1]:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__{suffix}\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    model = MetalSaltGNN_Ablation(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True,\n",
    "        selected_extras=selected_extras,\n",
    "        extras_dim=extras_dim\n",
    "    ).to(device)\n",
    "\n",
    "    checkpoint_name = f\"trained_models/Metal_salts_{config_name}_tmp_test.pt\"\n",
    "    checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'top1_acc':  res_test['top1_acc'],\n",
    "        'top3_acc':  res_test['top3_acc'],\n",
    "        'top5_acc':  res_test['top5_acc'],\n",
    "        'top10_acc': res_test['top10_acc'],\n",
    "        'macro_f1':  res_test['macro_f1'],\n",
    "    })\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "# results è la tua lista di dict\n",
    "metrics = [\"top1_acc\",\"top3_acc\",\"top5_acc\",\"top10_acc\",\"macro_f1\"]\n",
    "\n",
    "print(\"==== Media ± Std sulle run ====\\n\")\n",
    "for metric in metrics:\n",
    "    values = [r[metric] for r in results]\n",
    "    mean = np.mean(values)\n",
    "    std  = np.std(values)\n",
    "    print(f\"{metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d770a8",
   "metadata": {},
   "source": [
    "# real word experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59b92e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mofstructure import structure, mofdeconstructor\n",
    "from mofstructure.filetyper import load_iupac_names\n",
    "from fairmofsyncondition.read_write import cheminfo2iupac, coords_library, filetyper\n",
    "from ase.data import atomic_numbers\n",
    "from ase.io import read\n",
    "import torch\n",
    "\n",
    "\n",
    "inchi_corrector = {\n",
    "    \"FDTQOZYHNDMJCM-UHFFFAOYSA-N\":\"benzene-1,4-dicarboxylic acid\"\n",
    "}\n",
    "def get_ligand_iupacname(ligand_inchi):\n",
    "    print(ligand_inchi)\n",
    "    name = load_iupac_names().get(ligand_inchi, None)\n",
    "    if name is None:\n",
    "        pubchem = cheminfo2iupac.pubchem_to_inchikey(ligand_inchi, name='inchikey')\n",
    "        if pubchem is None:\n",
    "            name = inchi_corrector.get(ligand_inchi, ligand_inchi)\n",
    "        else:\n",
    "            pubchem.get('iupac_name', ligand_inchi)\n",
    "    return name\n",
    "\n",
    "\n",
    "def load_system(filename):\n",
    "    \"\"\"\n",
    "    A function to extract\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    os.makedirs('LigandsXYZ', exist_ok=True)\n",
    "    ase_data = read(filename)\n",
    "    structure_data = structure.MOFstructure(ase_atoms=ase_data)\n",
    "    _, ligands = structure_data.get_ligands()\n",
    "\n",
    "    inchikeys = [ligand.info.get('inchikey') for ligand in ligands]\n",
    "    for inchi, ligand in zip(inchikeys, ligands):\n",
    "        ligand.write(f'LigandsXYZ/{inchi}.xyz')\n",
    "    ligands_names = [get_ligand_iupacname(i) for i in inchikeys]\n",
    "    general = structure_data.get_oms()\n",
    "    oms = general.get('has_oms')\n",
    "    metal_symbols = general.get('metals')\n",
    "    metals_atomic_number = [atomic_numbers[i] for i in metal_symbols]\n",
    "    torch_data = coords_library.ase_to_pytorch_geometric(ase_data)\n",
    "    oms = torch.tensor([1 if  oms else 0], dtype=torch.int16)\n",
    "    torch_data.oms = oms\n",
    "    data['general'] = general\n",
    "    return torch_data, metals_atomic_number, inchikeys, ligands_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80a16c",
   "metadata": {},
   "source": [
    "# load cif structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b40a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): Zn(1); Metal was disconnected\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): Zn(1); Metal was disconnected\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDTQOZYHNDMJCM-UHFFFAOYSA-N\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"Zn2C43N6H29O8.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f30b5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESFABUZNSNZRT-UHFFFAOYSA-N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 19:25:53,706 - INFO - 'PUGREST.NotFound: No CID found that matches the given InChI key'\n",
      "/home/antonio/miniconda3/envs/fairmof/lib/python3.11/site-packages/pymatgen/io/cif.py:1606: FutureWarning: We strongly discourage using implicit binary/text `mode`, and this would not be allowed after 2025-06-01. I.e. you should pass t/b in `mode`.\n",
      "  with zopen(filename, mode=mode) as file:\n"
     ]
    }
   ],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"ZnC5HO5.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177ee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd1229a",
   "metadata": {},
   "source": [
    "# add additional info\n",
    "## atomic one-hot oms cordinates crystal_system space_group_number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17791fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): Zn(1); Metal was disconnected\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): Zn(1); Metal was disconnected\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDTQOZYHNDMJCM-UHFFFAOYSA-N\n",
      "Top-10 predicted metal salts for EDUSIF.cif:\n",
      "Zn(NO3)2.3H2O: 0.9694\n",
      "Zn(NO3)2.6H2O: 0.0179\n",
      "ZnCO3: 0.0040\n",
      "ZnSO4·6H2O: 0.0031\n",
      "ZnI2: 0.0017\n",
      "Zn(CH3COO)2·2H2O: 0.0013\n",
      "ZnCl2: 0.0012\n",
      "Zn(OAc)2·2H2O: 0.0007\n",
      "MnCl2·4H2O: 0.0003\n",
      "Zn(NO3)2: 0.0001\n"
     ]
    }
   ],
   "source": [
    "name_mof = \"EDUSIF.cif\"\n",
    "torch_data, metal_atomic_number, inch, lig = load_system(name_mof)\n",
    "\n",
    "\n",
    "d = torch_data\n",
    "\n",
    "# =======================\n",
    "# Parte 1: atomic one-hot\n",
    "# =======================\n",
    "node_features = d.x.numpy()\n",
    "atom_num = node_features[:, 0].astype(int)\n",
    "a, b = np.unique(atom_num, return_counts=True)\n",
    "emb = torch.zeros(120)\n",
    "for aa, bb in zip(a, b):\n",
    "    emb[aa] = bb\n",
    "d.atomic_one_hot = emb\n",
    "\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Parte 2: struttura ASE\n",
    "# =======================\n",
    "ase_atoms = pytorch_geometric_to_ase(d)\n",
    "stru = MOFstructure(ase_atoms)\n",
    "pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "\n",
    "# =======================\n",
    "# Parte 3: OMS\n",
    "# =======================\n",
    "emb = torch.zeros(96)\n",
    "tmp_dict = dict()\n",
    "for i in stru.get_oms()[\"metal_info\"]:\n",
    "    cord = i[\"coordination_number\"]\n",
    "    metal = i[\"metal\"]\n",
    "\n",
    "    if metal in tmp_dict:\n",
    "        if cord > tmp_dict[metal]:\n",
    "            tmp_dict[metal] = cord\n",
    "    else:\n",
    "        tmp_dict[metal] = cord\n",
    "\n",
    "for i, j in tmp_dict.items():\n",
    "    emb[convert_metals[i]] = j\n",
    "d.cordinates = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 4: spazio e sistema cristallino\n",
    "# =======================\n",
    "sga = SpacegroupAnalyzer(pymat)\n",
    "space_group_number = sga.get_space_group_number()\n",
    "emb = torch.zeros(231)\n",
    "emb[space_group_number] = 1\n",
    "d.space_group_number = emb\n",
    "\n",
    "get_crystal_system = sga.get_crystal_system()\n",
    "emb = torch.zeros(7)\n",
    "emb[convert_struct[get_crystal_system]] = 1\n",
    "d.crystal_system = emb\n",
    "# =======================\n",
    "# Parte 5: altri attributi\n",
    "# =======================\n",
    "d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\", \"cordinates\", \"oms\",\"space_group_number\"]\n",
    "model = MetalSaltGNN_Ablation(\n",
    "    node_in_dim=node_in_dim,\n",
    "    edge_in_dim=edge_in_dim,\n",
    "    lattice_in_dim=lattice_in_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    num_gnn_layers=4,\n",
    "    num_lattice_layers=2,\n",
    "    num_mlp_layers=2,\n",
    "    dropout=dropout,\n",
    "    use_batchnorm=True,\n",
    "    selected_extras=selected_extras,\n",
    "    extras_dim=extras_dim\n",
    ").to(device)\n",
    "\n",
    "checkpoint_name = f\"trained_models/Metal_salts_{config_name}_tmp_test.pt\"\n",
    "checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pred = model(d.to(device))\n",
    "\n",
    "# trasformo in probabilità (softmax sulla dimensione delle classi)\n",
    "probs = F.softmax(pred, dim=1)\n",
    "\n",
    "# ordino gli indici in ordine decrescente\n",
    "idx_desc = probs.argsort(dim=1, descending=True)[0]\n",
    "\n",
    "# stampo top-20 classi e probabilità\n",
    "\n",
    "print(f\"Top-10 predicted metal salts for {name_mof}:\")\n",
    "for i in idx_desc[:10]:\n",
    "    class_name = filetyper.category_names()[\"metal_salts\"][i.item()]\n",
    "    probability = probs[0, i].item()\n",
    "    print(f\"{class_name}: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d6ad936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESFABUZNSNZRT-UHFFFAOYSA-N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 19:35:41,460 - INFO - 'PUGREST.NotFound: No CID found that matches the given InChI key'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 predicted metal salts for ZnC5HO5.cif:\n",
      "Zn(NO3)2.3H2O: 0.5633\n",
      "ZnCl2: 0.2331\n",
      "Zn(OAc)2·2H2O: 0.0657\n",
      "ZnSO4·6H2O: 0.0542\n",
      "Zn(CH3COO)2·2H2O: 0.0163\n",
      "Zn(NO3)2.6H2O: 0.0148\n",
      "ZnCO3: 0.0129\n",
      "Zn(NO3)2: 0.0070\n",
      "ZnSO4·7H2O: 0.0067\n",
      "Zn(OAc)2: 0.0055\n"
     ]
    }
   ],
   "source": [
    "name_mof = \"ZnC5HO5.cif\"\n",
    "torch_data, metal_atomic_number, inch, lig = load_system(name_mof)\n",
    "\n",
    "\n",
    "d = torch_data\n",
    "\n",
    "# =======================\n",
    "# Parte 1: atomic one-hot\n",
    "# =======================\n",
    "node_features = d.x.numpy()\n",
    "atom_num = node_features[:, 0].astype(int)\n",
    "a, b = np.unique(atom_num, return_counts=True)\n",
    "emb = torch.zeros(120)\n",
    "for aa, bb in zip(a, b):\n",
    "    emb[aa] = bb\n",
    "d.atomic_one_hot = emb\n",
    "\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Parte 2: struttura ASE\n",
    "# =======================\n",
    "ase_atoms = pytorch_geometric_to_ase(d)\n",
    "stru = MOFstructure(ase_atoms)\n",
    "pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "\n",
    "# =======================\n",
    "# Parte 3: OMS\n",
    "# =======================\n",
    "emb = torch.zeros(96)\n",
    "tmp_dict = dict()\n",
    "for i in stru.get_oms()[\"metal_info\"]:\n",
    "    cord = i[\"coordination_number\"]\n",
    "    metal = i[\"metal\"]\n",
    "\n",
    "    if metal in tmp_dict:\n",
    "        if cord > tmp_dict[metal]:\n",
    "            tmp_dict[metal] = cord\n",
    "    else:\n",
    "        tmp_dict[metal] = cord\n",
    "\n",
    "for i, j in tmp_dict.items():\n",
    "    emb[convert_metals[i]] = j\n",
    "d.cordinates = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 4: spazio e sistema cristallino\n",
    "# =======================\n",
    "sga = SpacegroupAnalyzer(pymat)\n",
    "space_group_number = sga.get_space_group_number()\n",
    "emb = torch.zeros(231)\n",
    "emb[space_group_number] = 1\n",
    "d.space_group_number = emb\n",
    "\n",
    "get_crystal_system = sga.get_crystal_system()\n",
    "emb = torch.zeros(7)\n",
    "emb[convert_struct[get_crystal_system]] = 1\n",
    "d.crystal_system = emb\n",
    "# =======================\n",
    "# Parte 5: altri attributi\n",
    "# =======================\n",
    "d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\", \"cordinates\", \"oms\",\"space_group_number\"]\n",
    "model = MetalSaltGNN_Ablation(\n",
    "    node_in_dim=node_in_dim,\n",
    "    edge_in_dim=edge_in_dim,\n",
    "    lattice_in_dim=lattice_in_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    num_gnn_layers=4,\n",
    "    num_lattice_layers=2,\n",
    "    num_mlp_layers=2,\n",
    "    dropout=dropout,\n",
    "    use_batchnorm=True,\n",
    "    selected_extras=selected_extras,\n",
    "    extras_dim=extras_dim\n",
    ").to(device)\n",
    "\n",
    "checkpoint_name = f\"trained_models/Metal_salts_{config_name}_tmp_test.pt\"\n",
    "checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pred = model(d.to(device))\n",
    "\n",
    "# trasformo in probabilità (softmax sulla dimensione delle classi)\n",
    "probs = F.softmax(pred, dim=1)\n",
    "\n",
    "# ordino gli indici in ordine decrescente\n",
    "idx_desc = probs.argsort(dim=1, descending=True)[0]\n",
    "\n",
    "# stampo top-20 classi e probabilità\n",
    "\n",
    "print(f\"Top-10 predicted metal salts for {name_mof}:\")\n",
    "for i in idx_desc[:10]:\n",
    "    class_name = filetyper.category_names()[\"metal_salts\"][i.item()]\n",
    "    probability = probs[0, i].item()\n",
    "    print(f\"{class_name}: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "287b3565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1); C(3)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1); C(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGFJDEHFNMWYBD-OWOJBTEDSA-N\n",
      "VIORWCNXRPKALR-UHFFFAOYSA-N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 19:35:51,659 - INFO - 'PUGREST.NotFound: No CID found that matches the given InChI key'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 predicted metal salts for Zn2C43N6H29O8.cif:\n",
      "Zn(NO3)2.3H2O: 0.6947\n",
      "Zn(NO3)2.6H2O: 0.1882\n",
      "Zn(OAc)2·2H2O: 0.0278\n",
      "ZnCO3: 0.0243\n",
      "ZnCl2: 0.0206\n",
      "ZnSO4·6H2O: 0.0109\n",
      "ZnSO4·7H2O: 0.0088\n",
      "Zn(CH3COO)2·2H2O: 0.0060\n",
      "Zn(NO3)2: 0.0050\n",
      "Zn(ClO4)2·6H2O: 0.0043\n"
     ]
    }
   ],
   "source": [
    "name_mof = \"Zn2C43N6H29O8.cif\"\n",
    "torch_data, metal_atomic_number, inch, lig = load_system(name_mof)\n",
    "\n",
    "\n",
    "d = torch_data\n",
    "\n",
    "# =======================\n",
    "# Parte 1: atomic one-hot\n",
    "# =======================\n",
    "node_features = d.x.numpy()\n",
    "atom_num = node_features[:, 0].astype(int)\n",
    "a, b = np.unique(atom_num, return_counts=True)\n",
    "emb = torch.zeros(120)\n",
    "for aa, bb in zip(a, b):\n",
    "    emb[aa] = bb\n",
    "d.atomic_one_hot = emb\n",
    "\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Parte 2: struttura ASE\n",
    "# =======================\n",
    "ase_atoms = pytorch_geometric_to_ase(d)\n",
    "stru = MOFstructure(ase_atoms)\n",
    "pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "\n",
    "# =======================\n",
    "# Parte 3: OMS\n",
    "# =======================\n",
    "emb = torch.zeros(96)\n",
    "tmp_dict = dict()\n",
    "for i in stru.get_oms()[\"metal_info\"]:\n",
    "    cord = i[\"coordination_number\"]\n",
    "    metal = i[\"metal\"]\n",
    "\n",
    "    if metal in tmp_dict:\n",
    "        if cord > tmp_dict[metal]:\n",
    "            tmp_dict[metal] = cord\n",
    "    else:\n",
    "        tmp_dict[metal] = cord\n",
    "\n",
    "for i, j in tmp_dict.items():\n",
    "    emb[convert_metals[i]] = j\n",
    "d.cordinates = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 4: spazio e sistema cristallino\n",
    "# =======================\n",
    "sga = SpacegroupAnalyzer(pymat)\n",
    "space_group_number = sga.get_space_group_number()\n",
    "emb = torch.zeros(231)\n",
    "emb[space_group_number] = 1\n",
    "d.space_group_number = emb\n",
    "\n",
    "get_crystal_system = sga.get_crystal_system()\n",
    "emb = torch.zeros(7)\n",
    "emb[convert_struct[get_crystal_system]] = 1\n",
    "d.crystal_system = emb\n",
    "# =======================\n",
    "# Parte 5: altri attributi\n",
    "# =======================\n",
    "d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "\n",
    "selected_extras = [\"atomic_one_hot\", \"cordinates\", \"oms\",\"space_group_number\"]\n",
    "model = MetalSaltGNN_Ablation(\n",
    "    node_in_dim=node_in_dim,\n",
    "    edge_in_dim=edge_in_dim,\n",
    "    lattice_in_dim=lattice_in_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    num_gnn_layers=4,\n",
    "    num_lattice_layers=2,\n",
    "    num_mlp_layers=2,\n",
    "    dropout=dropout,\n",
    "    use_batchnorm=True,\n",
    "    selected_extras=selected_extras,\n",
    "    extras_dim=extras_dim\n",
    ").to(device)\n",
    "\n",
    "checkpoint_name = f\"trained_models/Metal_salts_{config_name}_tmp_test.pt\"\n",
    "checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pred = model(d.to(device))\n",
    "\n",
    "# trasformo in probabilità (softmax sulla dimensione delle classi)\n",
    "probs = F.softmax(pred, dim=1)\n",
    "\n",
    "# ordino gli indici in ordine decrescente\n",
    "idx_desc = probs.argsort(dim=1, descending=True)[0]\n",
    "\n",
    "# stampo top-20 classi e probabilità\n",
    "\n",
    "print(f\"Top-10 predicted metal salts for {name_mof}:\")\n",
    "for i in idx_desc[:10]:\n",
    "    class_name = filetyper.category_names()[\"metal_salts\"][i.item()]\n",
    "    probability = probs[0, i].item()\n",
    "    print(f\"{class_name}: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf14cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d23b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081c6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c92c1711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[114, 558, 354, 224,  31, 384, 577, 400, 646, 642, 552, 510, 435, 691,\n",
       "         434,  37, 503, 634, 742, 454, 791, 583, 131, 687, 579, 700, 569, 477,\n",
       "         204, 632, 694, 467, 414, 759, 463, 781, 242, 428, 775, 783, 254, 399,\n",
       "         201, 726, 645, 418, 778, 711, 462, 476, 333, 189, 524, 512,   3, 319,\n",
       "         355, 659, 619, 458, 139, 548, 290, 770, 740, 654, 352, 277, 729, 137,\n",
       "         234,  80,   9, 371, 688, 436, 484, 184, 640, 656,  61, 673, 735, 119,\n",
       "           0, 391, 707,  18, 433, 701, 357, 156, 773, 574,  28, 370,  89, 518,\n",
       "         609,  48, 182,  53, 615, 340,  39, 490, 716,  84, 712,  96, 514, 163,\n",
       "         592,  35, 123, 560, 221, 451, 507, 703, 255, 564, 380, 505,  75, 101,\n",
       "         541, 698, 303, 167, 172, 145, 478, 229, 417, 422, 442, 527, 105, 710,\n",
       "         113,  81, 526,  20, 452, 644, 214, 603, 643,  46, 407, 180, 513,  92,\n",
       "         348, 616, 720, 753, 471, 359, 318,  50, 421, 263,   6, 671, 232,  12,\n",
       "         200, 724, 252, 402, 153, 210,   7, 282, 733, 660, 289, 260, 774, 276,\n",
       "         482, 280, 183, 607, 571, 246, 780, 624, 121, 494, 534, 620, 523, 448,\n",
       "         419, 677, 718, 573, 372, 107, 697, 680, 401,  70, 437, 658, 612, 168,\n",
       "         679, 723, 406, 584, 299, 767, 475, 447, 150, 147,  64, 550, 762, 611,\n",
       "          83, 360,  79, 522, 544,  27, 493, 373, 212, 610, 465, 161, 102, 225,\n",
       "         227, 765,  86, 213,  62, 545, 639, 689, 323, 647, 110, 109, 199, 581,\n",
       "         492,  72, 695, 533, 165, 377, 216, 300, 124, 439, 423, 617, 575, 748,\n",
       "         587, 618,  10, 244, 515, 495,   1, 387,  71, 568, 125, 453, 444, 790,\n",
       "         117, 238,  14, 230, 606,  32, 425, 127, 257, 146, 310, 633, 374, 287,\n",
       "         259, 508, 329, 440, 325, 788, 714, 553, 267, 530, 194, 115,  24, 713,\n",
       "          11, 100, 271, 320, 500, 717, 485, 388, 521, 531, 630, 570, 782, 738,\n",
       "         196, 241, 250, 764, 324, 175, 330, 608, 461,  90, 288, 335, 705, 750,\n",
       "         249, 635, 511, 709,  63, 464, 722, 166, 306,  23, 648, 235, 203, 292,\n",
       "         685, 112, 169,  25, 327, 317, 149, 554,  41, 760, 525,   2, 586, 185,\n",
       "         410, 218, 734, 661,  97, 430, 479,  40,   5, 285, 593, 692,  87, 120,\n",
       "         408, 766, 655, 559, 504, 681, 628,  19,  57, 540, 517, 307, 294, 686,\n",
       "         547, 601, 768,  91,  66, 140,  17, 789, 128,  42, 474, 328, 240,  52,\n",
       "         223, 596, 758, 576, 336, 621, 755, 393, 520, 350, 582, 341, 367,  29,\n",
       "         316, 409, 736, 135, 278, 279, 771, 262,  55, 483, 353,  77, 382,  49,\n",
       "          68, 470, 395, 179, 702, 186, 787, 173, 509, 785, 566, 693,  38, 174,\n",
       "         719,  22, 265,  67, 663, 389, 151, 386, 162, 460, 641, 466,  47, 247,\n",
       "         756, 629, 108, 772, 160, 358, 708, 369, 784, 487, 449, 728, 420, 217,\n",
       "          45, 682, 557, 678, 614,  58, 245, 155, 106, 580, 291, 197, 148, 598,\n",
       "         334, 528, 489, 379, 657, 266, 304, 653, 752, 604, 732, 496, 321, 535,\n",
       "         269, 667, 364, 415, 104, 243, 385,  34, 594, 187, 152,  26, 312, 258,\n",
       "         219, 761, 666, 542, 441, 506, 551, 273, 141,  59, 539, 130, 549, 133,\n",
       "         438,  98, 572, 164, 749, 404, 375, 305, 198, 779, 332, 209, 144, 727,\n",
       "         233, 118, 342, 314, 308, 446, 491, 411, 226, 498, 786,  51, 136, 171,\n",
       "         561, 481, 207, 211, 253, 501, 763, 427, 111, 138, 231, 529, 368, 412,\n",
       "         339, 256, 567, 103, 190, 743,  36, 302, 649, 602, 228, 450, 488, 664,\n",
       "         445, 683, 543, 424, 416, 706, 625, 215, 499, 158, 337, 272, 192, 516,\n",
       "         613, 563, 322, 473, 715,  78,  43, 181, 777,   4, 650, 293,   8, 248,\n",
       "         585, 326, 623, 397, 208, 362, 275, 668, 239, 757, 721, 704,  16, 159,\n",
       "         669, 651, 590, 751, 309, 296, 459, 599, 546, 206, 366, 696, 538, 349,\n",
       "         636, 631, 754, 236, 626, 745, 365, 268,  73, 562, 456, 363, 134, 398,\n",
       "         776, 356, 670, 284,  94, 394, 270, 295,  74, 597, 588, 432, 565, 188,\n",
       "         486, 191, 351, 431, 595, 684, 343, 143, 178, 383, 381,  95, 361, 264,\n",
       "         346, 251, 157, 344, 378, 455, 274, 519, 396,  76, 390, 298, 237, 261,\n",
       "          88, 154, 315, 195, 281, 638, 122, 457, 126, 672,  30, 555, 589, 347,\n",
       "          21, 376, 222, 652, 338, 297, 578, 283, 502,  82,  54, 403, 331,  13,\n",
       "         730, 311, 429, 301, 472, 170, 622, 741,  15, 731, 313, 142,  33, 480,\n",
       "          85,  99, 469, 392, 468, 132, 405,  65, 176, 675, 537,  69, 676,  56,\n",
       "         690, 699, 747, 737, 536, 532, 497, 443, 202,  93, 665, 662, 177, 345,\n",
       "         674, 129, 591, 769, 746, 286, 739, 220, 413, 725, 556, 627, 600, 116,\n",
       "         605,  44, 426, 193,  60, 637, 744, 205]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a54a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(d.to(device))\n",
    "prx = \"Zn\"\n",
    "\n",
    "c = 0\n",
    "for i in pred.argsort()[0]:\n",
    "    a = filetyper.category_names()[\"metal_salts\"][i.item()]\n",
    "    if a[:2] == prx:\n",
    "        print(a)\n",
    "        c = c +1  \n",
    "    if c == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e96d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ad21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairmof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
