{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464f94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/miniconda3/envs/fairmof/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_pyg_obj\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils import fix_target_shapes,remove_unused_onehot_columns,set_seed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afb0dd",
   "metadata": {},
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35b9198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset. Note the dataset is not included in the git repo, you have to download it!\n",
    "data_in = load_pyg_obj(path_to_mdb=\"../../data/mof_syncondition_data/\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "#  Train / Validation / Test Split (80/10/10)\n",
    "dataset = fix_target_shapes(data_in,\"metal_salts\")\n",
    "dataset = remove_unused_onehot_columns(dataset,\"metal_salts\")\n",
    "Y_size = max([torch.argmax(d[\"metal_salts\"]).item() for d in dataset])\n",
    "set_seed(seed=42) # 42\n",
    "num_classes = Y_size+1\n",
    "input_dim = dataset[0].x.shape[1]\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b26659",
   "metadata": {},
   "source": [
    "# Define the GNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7be2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "### GNN architecture \n",
    "\n",
    "class MetalSaltGNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in_dim,\n",
    "        edge_in_dim,\n",
    "        lattice_in_dim,\n",
    "        hidden_dim,\n",
    "        num_classes,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=0.2,\n",
    "        use_batchnorm=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Edge encoder\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # GINE layers: ora usiamo GINEConv\n",
    "        self.gnn_layers = nn.ModuleList()\n",
    "        self.gnn_bns = nn.ModuleList() if use_batchnorm else None\n",
    "\n",
    "        for i in range(num_gnn_layers):\n",
    "            in_dim = node_in_dim if i == 0 else hidden_dim\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "            )\n",
    "            self.gnn_layers.append(GINEConv(mlp, edge_dim=hidden_dim))  # <-- aggiunto edge_dim!\n",
    "            if use_batchnorm:\n",
    "                self.gnn_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # Lattice encoder come MLP profondo parametrico\n",
    "        lattice_layers = []\n",
    "        in_dim = lattice_in_dim\n",
    "        for _ in range(num_lattice_layers - 1):\n",
    "            lattice_layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            lattice_layers.append(nn.ReLU())\n",
    "            if use_batchnorm:\n",
    "                lattice_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            in_dim = hidden_dim\n",
    "        lattice_layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.lattice_encoder = nn.Sequential(*lattice_layers)\n",
    "\n",
    "        # Final MLP layers\n",
    "        mlp_layers = []\n",
    "        in_dim = hidden_dim * 2  # x_pool + lattice_feat\n",
    "        for _ in range(num_mlp_layers - 1):\n",
    "            mlp_layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            if use_batchnorm:\n",
    "                mlp_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            mlp_layers.append(nn.Dropout(p=dropout))\n",
    "            in_dim = hidden_dim\n",
    "        mlp_layers.append(nn.Linear(in_dim, num_classes))\n",
    "        self.final_mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch, lattice = (\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch, data.lattice\n",
    "        )\n",
    "\n",
    "        # Encode edge_attr\n",
    "        edge_feat = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # GINE layers\n",
    "        for i, conv in enumerate(self.gnn_layers):\n",
    "            x = conv(x, edge_index, edge_feat)  # ora usiamo edge_feat nella propagazione!\n",
    "            x = F.relu(x)\n",
    "            if self.use_batchnorm:\n",
    "                x = self.gnn_bns[i](x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Pooling globale\n",
    "        x_pool = global_mean_pool(x, batch)\n",
    "\n",
    "        # Lattice processing\n",
    "        lattice_flat = lattice.reshape(-1, 3 * 3)  # batch_size x 9\n",
    "        lattice_feat = self.lattice_encoder(lattice_flat)\n",
    "\n",
    "        # Combine and classify\n",
    "        out = torch.cat([x_pool, lattice_feat], dim=1)\n",
    "        out = self.final_mlp(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Train and eval functions \n",
    "\n",
    "\n",
    "########################################## training and eval\n",
    "# TRAINING FUNCTION\n",
    "def train(model, loader, criterion, optimizer, device,target):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if target == \"metal_salts\":\n",
    "            loss = criterion(out, data.metal_salts.squeeze())\n",
    "        elif target == \"ligands\":\n",
    "            loss = criterion(out, data.ligands.squeeze())\n",
    "        else:\n",
    "            print(\"specify target\")\n",
    "            assert False\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device, target_name):\n",
    "    model.eval()\n",
    "    correct_top1 = 0\n",
    "    correct_top10 = 0\n",
    "    correct_top3 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)  # [batch_size, num_classes]\n",
    "\n",
    "            # Predizioni\n",
    "            pred_top1 = out.argmax(dim=1)  # [batch_size]\n",
    "            pred_top10 = out.topk(10, dim=1).indices  # [batch_size, 10]\n",
    "            pred_top5 = out.topk(5, dim=1).indices  # [batch_size, 10]\n",
    "            pred_top3 = out.topk(3, dim=1).indices  # [batch_size, 10]\n",
    "\n",
    "            # Target\n",
    "            if target_name == \"metal_salts\":\n",
    "                target = data.metal_salts.argmax(dim=1)  # [batch_size]\n",
    "            else:\n",
    "                print(\"specify target\")\n",
    "                assert False\n",
    "\n",
    "            # Salva per F1\n",
    "            all_preds.append(pred_top1.cpu())\n",
    "            all_targets.append(target.cpu())\n",
    "\n",
    "            # Top-1\n",
    "            correct_top1 += (pred_top1 == target).sum().item()\n",
    "            # Top-10\n",
    "            correct_top10 += (pred_top10 == target.unsqueeze(1)).any(dim=1).sum().item()\n",
    "            correct_top3 += (pred_top3 == target.unsqueeze(1)).any(dim=1).sum().item()\n",
    "            correct_top5 += (pred_top5 == target.unsqueeze(1)).any(dim=1).sum().item()\n",
    "\n",
    "            total += data.num_graphs\n",
    "\n",
    "    # Concatenate tutte le predizioni e target in un unico tensore/vettore\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    # Calcola macro-F1\n",
    "    macro_f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'top1_acc': correct_top1 / total,\n",
    "        'top10_acc': correct_top10 / total,\n",
    "        'top3_acc': correct_top3 / total,\n",
    "        'top5_acc': correct_top5 / total,\n",
    "        'macro_f1': macro_f1\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ef581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X edge_indes, edge_attr, lattice\n",
    "\n",
    "# Example values: adjust to match your actual data dimensions\n",
    "node_in_dim = data_in[0].x.shape[1]\n",
    "edge_in_dim = data_in[0].edge_attr.shape[1]\n",
    "lattice_in_dim = 9  # 3x3 lattice flattened\n",
    "hidden_dim = 32\n",
    "dropout = 0.25\n",
    "\n",
    "number_of_runs = [0,1,2,3,4]  # due seed come richiesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3193e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training config: HID32_DO0.25_SEED0_X_edgeAttr_lattice_tmp =====\n",
      "Early stopping at epoch 30 (no improvement for 5 evals).\n",
      "HID32_DO0.25_SEED0_X_edgeAttr_lattice_tmp TEST: top10_acc=0.5261, top5_acc=0.4268, top3_acc=0.3573, macro_f1=0.0243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}_X_edgeAttr_lattice\"\n",
    "    print(f\"\\n===== Training config: {config_name} =====\")\n",
    "    \n",
    "    # Seed per riproducibilità\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Modello\n",
    "    model = MetalSaltGNN(\n",
    "        node_in_dim, edge_in_dim, lattice_in_dim, hidden_dim, num_classes,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=3,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    os.makedirs(\"tmp\", exist_ok=True)\n",
    "    checkpoint_name = f\"tmp/Metal_salts_{config_name}.pt\"\n",
    "    patience = 50\n",
    "    eval_every = 5\n",
    "    best_metric = 0.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 1001):\n",
    "        loss = train(model, train_loader, criterion, optimizer, device, \"metal_salts\")\n",
    "        if epoch % eval_every == 0:\n",
    "            res = evaluate(model, val_loader, device, \"metal_salts\")\n",
    "            macro_top_k = res[\"top5_acc\"]\n",
    "\n",
    "            if macro_top_k > best_metric:\n",
    "                best_metric = macro_top_k\n",
    "                epochs_no_improve = 0\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_metric': best_metric\n",
    "                }, checkpoint_name)\n",
    "            else:\n",
    "                epochs_no_improve += eval_every\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} (no improvement for {patience} evals).\")\n",
    "                break\n",
    "\n",
    "    # Carica best model e valuta su test\n",
    "    checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "\n",
    "    # Logga i risultati\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'top1_acc': res_test['top1_acc'],\n",
    "        'top10_acc': res_test['top10_acc'],\n",
    "        'top5_acc': res_test['top5_acc'],\n",
    "        'top3_acc': res_test['top3_acc'],\n",
    "        'macro_f1': res_test['macro_f1']\n",
    "    })\n",
    "    print(f\"{config_name} TEST: top10_acc={res_test['top10_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f}, macro_f1={res_test['macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db04f4",
   "metadata": {},
   "source": [
    "# Load trained models and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22757017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluating config: HID32_DO0.25_SEED0_X_edgeAttr_lattice =====\n",
      "HID32_DO0.25_SEED0_X_edgeAttr_lattice TEST: top10_acc=0.6650, top5_acc=0.5757, top3_acc=0.4839, macro_f1=0.0813\n",
      "\n",
      "===== Evaluating config: HID32_DO0.25_SEED1_X_edgeAttr_lattice =====\n",
      "HID32_DO0.25_SEED1_X_edgeAttr_lattice TEST: top10_acc=0.6675, top5_acc=0.5459, top3_acc=0.4665, macro_f1=0.0622\n",
      "\n",
      "===== Evaluating config: HID32_DO0.25_SEED2_X_edgeAttr_lattice =====\n",
      "HID32_DO0.25_SEED2_X_edgeAttr_lattice TEST: top10_acc=0.6650, top5_acc=0.5533, top3_acc=0.4839, macro_f1=0.0677\n",
      "\n",
      "===== Evaluating config: HID32_DO0.25_SEED3_X_edgeAttr_lattice =====\n",
      "HID32_DO0.25_SEED3_X_edgeAttr_lattice TEST: top10_acc=0.6526, top5_acc=0.5310, top3_acc=0.4665, macro_f1=0.0660\n",
      "\n",
      "===== Evaluating config: HID32_DO0.25_SEED4_X_edgeAttr_lattice =====\n",
      "HID32_DO0.25_SEED4_X_edgeAttr_lattice TEST: top10_acc=0.6749, top5_acc=0.5484, top3_acc=0.4864, macro_f1=0.0635\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}_X_edgeAttr_lattice\"\n",
    "    print(f\"\\n===== Evaluating config: {config_name} =====\")\n",
    "    \n",
    "    # Seed per riproducibilità\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Modello\n",
    "    model = MetalSaltGNN(\n",
    "        node_in_dim, edge_in_dim, lattice_in_dim, hidden_dim, num_classes,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=3,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True\n",
    "    ).to(device)\n",
    "\n",
    "    os.makedirs(\"tmp\", exist_ok=True)\n",
    "    checkpoint_name = f\"tmp/Metal_salts_{config_name}.pt\"\n",
    "        # Carica best model e valuta su test\n",
    "    checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "\n",
    "    # Logga i risultati\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'top1_acc': res_test['top1_acc'],\n",
    "        'top10_acc': res_test['top10_acc'],\n",
    "        'top5_acc': res_test['top5_acc'],\n",
    "        'top3_acc': res_test['top3_acc'],\n",
    "        'macro_f1': res_test['macro_f1']\n",
    "    })\n",
    "    print(f\"{config_name} TEST: top10_acc={res_test['top10_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f}, macro_f1={res_test['macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a89f6466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config: HID32_DO0.25_X_edgeAttr_lattice\n",
      "top1_acc \t= 0.31 ± 0.02\n",
      "top10_acc \t= 0.67 ± 0.01\n",
      "top5_acc \t= 0.55 ± 0.02\n",
      "top3_acc \t= 0.48 ± 0.01\n",
      "macro_f1 \t= 0.07 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# normalizza config togliendo il seed\n",
    "df['base_config'] = df['config'].str.replace(r'_SEED\\d+', '', regex=True)\n",
    "\n",
    "metrics = ['top1_acc','top10_acc','top5_acc','top3_acc','macro_f1']\n",
    "\n",
    "# calcolo mean e std per ogni base_config\n",
    "grouped = df.groupby('base_config')[metrics].agg(['mean','std'])\n",
    "\n",
    "# stampa formattata\n",
    "for cfg, row in grouped.iterrows():\n",
    "    print(f\"\\nConfig: {cfg}\")\n",
    "    for m in metrics:\n",
    "        mean = row[(m,'mean')]\n",
    "        std  = row[(m,'std')]\n",
    "        print(f\"{m} \\t= {mean:.2f} ± {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e9657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766db49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a8349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa363d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb3978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairmof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
