{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda9bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/miniconda3/envs/fairmof/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_pyg_obj\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import fix_target_shapes,remove_unused_onehot_columns,set_seed,filter_metals\n",
    "from mofstructure import mofdeconstructor\n",
    "\n",
    "from fairmofsyncondition.read_write.coords_library import pytorch_geometric_to_ase\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "\n",
    "convert_struct = {'cubic':0, 'hexagonal':1, 'monoclinic':2, 'orthorhombic':3, 'tetragonal':4,'triclinic':5, 'trigonal':6}\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a212130",
   "metadata": {},
   "source": [
    "# GNN for Metal Salt Prediction\n",
    "\n",
    "This code implements a **Graph Neural Network (GNN)** to predict metal salts, using:\n",
    "- **Node Features**  \n",
    "- **Edge Features**  \n",
    "- **Lattice**   \n",
    "- **Oms**\n",
    "- **Atomic number**\n",
    "---\n",
    "\n",
    "## Code Structure\n",
    "\n",
    "1. **Load the Data**  \n",
    "   Import and prepare the dataset for use in the model.\n",
    "\n",
    "2. **Define the GNN Model**  \n",
    "   Define the neural network architecture (layers, activation functions, etc.).\n",
    "\n",
    "3. **Train the Model**  \n",
    "   - Train the model on the dataset.  \n",
    "   - Save the trained GNN weights into the `tmp/` folder.  \n",
    "\n",
    "   ⚠️ **Note**:  \n",
    "   If you only want to **test the model** without re-training, you can **skip this section** and avoid running the training step.\n",
    "\n",
    "4. **Load and Evaluate the Model**  \n",
    "   - Load the trained model weights.  \n",
    "   - Evaluate the model performance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afb0dd",
   "metadata": {},
   "source": [
    "### 1) Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d29a2",
   "metadata": {},
   "source": [
    "\n",
    "### to get oms\n",
    "### stru.get_oms()[\"has_oms\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17366789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mofstructure.structure import MOFstructure\n",
    "# convert_metals = {j:i for i,j in enumerate(mofdeconstructor.transition_metals()[1:])}\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# set_seed(seed=42)\n",
    "\n",
    "# data_in = load_pyg_obj(path_to_mdb=\"../../data/mof_syncondition_data/\")\n",
    "# dataset = fix_target_shapes(data_in, \"metal_salts\")\n",
    "# dataset = remove_unused_onehot_columns(dataset, \"metal_salts\")\n",
    "\n",
    "\n",
    "# bad = []\n",
    "# good = []\n",
    "\n",
    "# c = 0\n",
    "# for d in dataset:\n",
    "#     if c % 100 == 0:\n",
    "#         print(c)\n",
    "#     c = c + 1\n",
    "\n",
    "#     try:\n",
    "#         # =======================\n",
    "#         # Parte 1: atomic one-hot\n",
    "#         # =======================\n",
    "#         node_features = d.x.numpy()\n",
    "#         atom_num = node_features[:, 0].astype(int)\n",
    "#         a, b = np.unique(atom_num, return_counts=True)\n",
    "#         emb = torch.zeros(120)\n",
    "#         for aa, bb in zip(a, b):\n",
    "#             emb[aa] = bb\n",
    "#         d.atomic_one_hot = emb\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 2: struttura ASE\n",
    "#         # =======================\n",
    "#         ase_atoms = pytorch_geometric_to_ase(d)\n",
    "#         stru = MOFstructure(ase_atoms)\n",
    "#         pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 3: OMS\n",
    "#         # =======================\n",
    "#         emb = torch.zeros(96)\n",
    "#         tmp_dict = dict()\n",
    "#         for i in stru.get_oms()[\"metal_info\"]:\n",
    "#             cord = i[\"coordination_number\"]\n",
    "#             metal = i[\"metal\"]\n",
    "\n",
    "#             if metal in tmp_dict:\n",
    "#                 if cord > tmp_dict[metal]:\n",
    "#                     tmp_dict[metal] = cord\n",
    "#             else:\n",
    "#                 tmp_dict[metal] = cord\n",
    "\n",
    "#         for i, j in tmp_dict.items():\n",
    "#             emb[convert_metals[i]] = j\n",
    "#         d.cordinates = emb\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 4: spazio e sistema cristallino\n",
    "#         # =======================\n",
    "#         sga = SpacegroupAnalyzer(pymat)\n",
    "#         space_group_number = sga.get_space_group_number()\n",
    "#         emb = torch.zeros(231)\n",
    "#         emb[space_group_number] = 1\n",
    "#         d.space_group_number = emb\n",
    "\n",
    "#         get_crystal_system = sga.get_crystal_system()\n",
    "#         emb = torch.zeros(7)\n",
    "#         emb[convert_struct[get_crystal_system]] = 1\n",
    "#         d.crystal_system = emb\n",
    "\n",
    "#         # =======================\n",
    "#         # Parte 5: altri attributi\n",
    "#         # =======================\n",
    "#         d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "#         por = stru.get_porosity()\n",
    "#         por = list(por.values())\n",
    "#         d.porosity = torch.tensor(por)\n",
    "\n",
    "#         d.modified_scherrer = None\n",
    "#         d.microstrain = None\n",
    "\n",
    "#         # Se arrivo qui senza eccezioni → struttura buona\n",
    "#         good.append(d)\n",
    "\n",
    "#     except Exception:\n",
    "#         bad.append(d)\n",
    "#         continue\n",
    "\n",
    "\n",
    "# import torch\n",
    "\n",
    "# torch.save(good, \"dataset_cleen_all_info.pt\")   # salva lista di Data\n",
    "# # poi\n",
    "# dataset = torch.load(\"dataset_cleen_all_info.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e283701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_data',\n",
       " 'dinga',\n",
       " 'fairmofsyncondition',\n",
       " 'officialGIT',\n",
       " 'Interactive_tool.png',\n",
       " 'new_data_v2',\n",
       " 'dataset_cleen_all_info.pt',\n",
       " 'test_data.lmdb',\n",
       " 'GIT',\n",
       " 'disegno-1.svg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38690ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ec87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are classess 122 3054\n"
     ]
    }
   ],
   "source": [
    "from mofstructure.structure import MOFstructure\n",
    "convert_metals = {j:i for i,j in enumerate(mofdeconstructor.transition_metals()[1:])}\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "set_seed(seed=42)\n",
    "dataset = torch.load(\"../../dataset_cleen_all_info.pt\")\n",
    "\n",
    "\n",
    "\n",
    "Y = []\n",
    "for d in dataset:\n",
    "    Y.append(d.metal_salts.argmax(dim=1).item())\n",
    "    \n",
    "a,b = np.unique(Y,return_counts=True)\n",
    "conv_y = {i:j for i,j in zip(a,b)}\n",
    "\n",
    "good = []\n",
    "for d in dataset:\n",
    "    if conv_y[d.metal_salts.argmax(dim=1).item()] > 5:\n",
    "        good.append(d)\n",
    "len(good)\n",
    "\n",
    "Y2 = []\n",
    "for d in good:\n",
    "    Y2.append(d.metal_salts.argmax(dim=1).item())\n",
    "    \n",
    "    \n",
    "print(\"There are classess\",len(np.unique(Y2)), len(Y2))\n",
    "\n",
    "\n",
    "dataset = good\n",
    "\n",
    "# Train/val/test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b26659",
   "metadata": {},
   "source": [
    "### 2) Define the GNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7be2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool,GINConv\n",
    "\n",
    "\n",
    "# ==================== Model ====================\n",
    "\n",
    "class MetalSaltGNN_v2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in_dim=4,     # da x.shape[1]\n",
    "        edge_in_dim=1,     # da edge_attr.shape[1]\n",
    "        lattice_in_dim=9,  # 3x3 flatten\n",
    "        hidden_dim=128,\n",
    "        num_classes=10,\n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=0.2,\n",
    "        use_batchnorm=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # --- Edge encoder (per GINE)\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # --- GINE layers\n",
    "        self.gnn_layers = nn.ModuleList()\n",
    "        self.gnn_bns = nn.ModuleList() if use_batchnorm else None\n",
    "        for i in range(num_gnn_layers):\n",
    "            in_dim = node_in_dim if i == 0 else hidden_dim\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.gnn_layers.append(GINEConv(mlp, edge_dim=hidden_dim))\n",
    "            if use_batchnorm:\n",
    "                self.gnn_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # --- Lattice encoder\n",
    "        lattice_layers = []\n",
    "        in_dim = lattice_in_dim\n",
    "        for _ in range(max(1, num_lattice_layers - 1)):\n",
    "            lattice_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                lattice_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            in_dim = hidden_dim\n",
    "        lattice_layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.lattice_encoder = nn.Sequential(*lattice_layers)\n",
    "\n",
    "        # --- Final MLP head\n",
    "        # Extra graph-level features\n",
    "        extra_dim = 120 + 231 + 7 + 1 + 8 + 96\n",
    "        final_in = hidden_dim * 2 + extra_dim\n",
    "\n",
    "        mlp_layers = []\n",
    "        in_dim = final_in\n",
    "        for _ in range(max(1, num_mlp_layers - 1)):\n",
    "            mlp_layers += [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "            if use_batchnorm:\n",
    "                mlp_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            mlp_layers.append(nn.Dropout(p=dropout))\n",
    "            in_dim = hidden_dim\n",
    "        mlp_layers.append(nn.Linear(in_dim, num_classes))\n",
    "        self.final_mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        lattice = data.lattice\n",
    "\n",
    "        # Per-graph extras\n",
    "        atomic_oh = data.atomic_one_hot.view(-1, 120)\n",
    "        sg_oh = data.space_group_number.view(-1, 231)\n",
    "        cs_oh = data.crystal_system.view(-1, 7)\n",
    "        oms = data.oms.view(-1, 1)\n",
    "        porosity = data.porosity.view(-1, 8)\n",
    "        coords = data.cordinates.view(-1, 96)\n",
    "\n",
    "        # Encode edges\n",
    "        e = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # GNN layers\n",
    "        for i, conv in enumerate(self.gnn_layers):\n",
    "            x = conv(x, edge_index, e)\n",
    "            x = F.relu(x)\n",
    "            if self.use_batchnorm:\n",
    "                x = self.gnn_bns[i](x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Global pooling\n",
    "        x_pool = global_mean_pool(x, batch)\n",
    "\n",
    "        # Lattice encoding\n",
    "        lattice = lattice.view(-1, 9)\n",
    "        lattice_feat = self.lattice_encoder(lattice)\n",
    "\n",
    "        # Concatenate everything\n",
    "        extras = torch.cat([atomic_oh, sg_oh, cs_oh, oms, porosity, coords], dim=1)\n",
    "        final_in = torch.cat([x_pool, lattice_feat, extras], dim=1)\n",
    "\n",
    "        out = self.final_mlp(final_in)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ==================== Train / Eval helpers ====================\n",
    "def train(model, loader, criterion, optimizer, device, target_name):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        # target expected one-hot per-graph -> class indices\n",
    "        target = torch.argmax(data[target_name], dim=1).long()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, target_name):\n",
    "    model.eval()\n",
    "    correct = {1: 0, 3: 0, 5: 0, 10: 0}\n",
    "    total = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        labels = torch.argmax(data[target_name], dim=1).long()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Top-k accuracy\n",
    "        _, pred = logits.topk(10, dim=1)\n",
    "        for k in correct.keys():\n",
    "            correct[k] += (pred[:, :k] == labels.view(-1, 1)).any(dim=1).sum().item()\n",
    "\n",
    "        # Per F1: usiamo solo la predizione top1\n",
    "        top1_preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(top1_preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    # Concatena\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    macro_f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average=\"macro\")\n",
    "\n",
    "    results = {f\"top{k}_acc\": correct[k] / max(1, total) for k in correct}\n",
    "    results[\"macro_f1\"] = macro_f1\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b9e6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_in_dim = dataset[0].x.shape[1]\n",
    "edge_in_dim = dataset[0].edge_attr.shape[1]\n",
    "lattice_in_dim = 9\n",
    "\n",
    "number_of_runs = [1,2,3]  # \n",
    "\n",
    "hidden_dim = 64\n",
    "dropout = 0.35\n",
    "\n",
    "\n",
    "Y_size = max([torch.argmax(d[\"metal_salts\"]).item() for d in dataset])\n",
    "num_classes = Y_size + 1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a12f7b",
   "metadata": {},
   "source": [
    "### 3) Train the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd47e73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training config: HID64_DO0.35_SEED1__X_edgeAttr_lattice_oms_AtomicNumber_structsym =====\n",
      "VAL: top1_acc=0.2984, top5_acc=0.5082, top3_acc=0.4689 macro_f1=0.0446\n",
      "VAL: top1_acc=0.4033, top5_acc=0.6623, top3_acc=0.5836 macro_f1=0.1178\n",
      "VAL: top1_acc=0.4754, top5_acc=0.6951, top3_acc=0.6262 macro_f1=0.1754\n",
      "VAL: top1_acc=0.4656, top5_acc=0.7213, top3_acc=0.6328 macro_f1=0.1563\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7410, top3_acc=0.6623 macro_f1=0.1809\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7443, top3_acc=0.6656 macro_f1=0.2034\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7574, top3_acc=0.6787 macro_f1=0.2044\n",
      "VAL: top1_acc=0.4787, top5_acc=0.7508, top3_acc=0.6557 macro_f1=0.1861\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7508, top3_acc=0.6459 macro_f1=0.1841\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7738, top3_acc=0.6787 macro_f1=0.1919\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7902, top3_acc=0.6656 macro_f1=0.2570\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7902, top3_acc=0.7049 macro_f1=0.2425\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7738, top3_acc=0.6918 macro_f1=0.2529\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7705, top3_acc=0.6885 macro_f1=0.2508\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7836, top3_acc=0.6984 macro_f1=0.2442\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7770, top3_acc=0.7082 macro_f1=0.2341\n",
      "VAL: top1_acc=0.5377, top5_acc=0.8098, top3_acc=0.7082 macro_f1=0.2700\n",
      "VAL: top1_acc=0.5213, top5_acc=0.7770, top3_acc=0.6951 macro_f1=0.2616\n",
      "VAL: top1_acc=0.5115, top5_acc=0.7836, top3_acc=0.6787 macro_f1=0.2618\n",
      "VAL: top1_acc=0.5311, top5_acc=0.7869, top3_acc=0.7115 macro_f1=0.2685\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7902, top3_acc=0.6918 macro_f1=0.2606\n",
      "VAL: top1_acc=0.5213, top5_acc=0.7836, top3_acc=0.6787 macro_f1=0.2886\n",
      "VAL: top1_acc=0.5344, top5_acc=0.7869, top3_acc=0.7016 macro_f1=0.2957\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7770, top3_acc=0.6852 macro_f1=0.2666\n",
      "VAL: top1_acc=0.5180, top5_acc=0.7803, top3_acc=0.7082 macro_f1=0.2541\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7869, top3_acc=0.6852 macro_f1=0.2734\n",
      "VAL: top1_acc=0.5082, top5_acc=0.8000, top3_acc=0.7049 macro_f1=0.2675\n",
      "Early stopping at epoch 135\n",
      "HID64_DO0.35_SEED1__X_edgeAttr_lattice_oms_AtomicNumber_structsym TEST: top1_acc=0.4641, top5_acc=0.7614, top3_acc=0.6601 macro_f1=0.2764\n",
      "\n",
      "===== Training config: HID64_DO0.35_SEED2__X_edgeAttr_lattice_oms_AtomicNumber_structsym =====\n",
      "VAL: top1_acc=0.2918, top5_acc=0.4426, top3_acc=0.4066 macro_f1=0.0401\n",
      "VAL: top1_acc=0.4197, top5_acc=0.6754, top3_acc=0.5967 macro_f1=0.1275\n",
      "VAL: top1_acc=0.4623, top5_acc=0.7148, top3_acc=0.6295 macro_f1=0.1375\n",
      "VAL: top1_acc=0.4721, top5_acc=0.7508, top3_acc=0.6557 macro_f1=0.1670\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7508, top3_acc=0.6459 macro_f1=0.1826\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7607, top3_acc=0.6656 macro_f1=0.2226\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7672, top3_acc=0.6754 macro_f1=0.1771\n",
      "VAL: top1_acc=0.5049, top5_acc=0.8098, top3_acc=0.6885 macro_f1=0.2225\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7836, top3_acc=0.6984 macro_f1=0.2347\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7770, top3_acc=0.6820 macro_f1=0.2374\n",
      "VAL: top1_acc=0.5311, top5_acc=0.7967, top3_acc=0.7016 macro_f1=0.2621\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7869, top3_acc=0.6951 macro_f1=0.2281\n",
      "VAL: top1_acc=0.5246, top5_acc=0.7902, top3_acc=0.6918 macro_f1=0.2377\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7869, top3_acc=0.6951 macro_f1=0.2509\n",
      "VAL: top1_acc=0.5148, top5_acc=0.7934, top3_acc=0.6885 macro_f1=0.2452\n",
      "VAL: top1_acc=0.5279, top5_acc=0.7803, top3_acc=0.6918 macro_f1=0.2432\n",
      "VAL: top1_acc=0.5246, top5_acc=0.7770, top3_acc=0.6918 macro_f1=0.2466\n",
      "VAL: top1_acc=0.5213, top5_acc=0.7902, top3_acc=0.7148 macro_f1=0.2424\n",
      "Early stopping at epoch 90\n",
      "HID64_DO0.35_SEED2__X_edgeAttr_lattice_oms_AtomicNumber_structsym TEST: top1_acc=0.4575, top5_acc=0.7484, top3_acc=0.6503 macro_f1=0.2492\n",
      "\n",
      "===== Training config: HID64_DO0.35_SEED3__X_edgeAttr_lattice_oms_AtomicNumber_structsym =====\n",
      "VAL: top1_acc=0.3344, top5_acc=0.4951, top3_acc=0.4328 macro_f1=0.0433\n",
      "VAL: top1_acc=0.4361, top5_acc=0.6525, top3_acc=0.5902 macro_f1=0.1388\n",
      "VAL: top1_acc=0.4525, top5_acc=0.7115, top3_acc=0.6197 macro_f1=0.1389\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7377, top3_acc=0.6492 macro_f1=0.1595\n",
      "VAL: top1_acc=0.4656, top5_acc=0.7180, top3_acc=0.6590 macro_f1=0.1664\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7443, top3_acc=0.6590 macro_f1=0.1902\n",
      "VAL: top1_acc=0.4689, top5_acc=0.7410, top3_acc=0.6557 macro_f1=0.1822\n",
      "VAL: top1_acc=0.4623, top5_acc=0.7607, top3_acc=0.6623 macro_f1=0.1853\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7508, top3_acc=0.6623 macro_f1=0.2203\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7475, top3_acc=0.6492 macro_f1=0.1864\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7672, top3_acc=0.6689 macro_f1=0.2133\n",
      "VAL: top1_acc=0.5049, top5_acc=0.7803, top3_acc=0.6820 macro_f1=0.2064\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7443, top3_acc=0.6590 macro_f1=0.2276\n",
      "VAL: top1_acc=0.4721, top5_acc=0.7770, top3_acc=0.6721 macro_f1=0.2046\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7770, top3_acc=0.6918 macro_f1=0.2190\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7607, top3_acc=0.6656 macro_f1=0.2092\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7934, top3_acc=0.6918 macro_f1=0.2148\n",
      "VAL: top1_acc=0.4820, top5_acc=0.7672, top3_acc=0.6918 macro_f1=0.1981\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7803, top3_acc=0.6852 macro_f1=0.2099\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7869, top3_acc=0.6852 macro_f1=0.2340\n",
      "VAL: top1_acc=0.4689, top5_acc=0.7902, top3_acc=0.6689 macro_f1=0.2054\n",
      "VAL: top1_acc=0.4885, top5_acc=0.8000, top3_acc=0.6754 macro_f1=0.2275\n",
      "VAL: top1_acc=0.4984, top5_acc=0.8098, top3_acc=0.6820 macro_f1=0.2263\n",
      "VAL: top1_acc=0.4754, top5_acc=0.7934, top3_acc=0.6984 macro_f1=0.2350\n",
      "VAL: top1_acc=0.5082, top5_acc=0.7869, top3_acc=0.6852 macro_f1=0.2407\n",
      "VAL: top1_acc=0.4918, top5_acc=0.7967, top3_acc=0.6984 macro_f1=0.2324\n",
      "VAL: top1_acc=0.5016, top5_acc=0.8098, top3_acc=0.6852 macro_f1=0.2431\n",
      "VAL: top1_acc=0.5016, top5_acc=0.7672, top3_acc=0.6885 macro_f1=0.2366\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7803, top3_acc=0.6885 macro_f1=0.2413\n",
      "VAL: top1_acc=0.5016, top5_acc=0.8000, top3_acc=0.6951 macro_f1=0.2462\n",
      "VAL: top1_acc=0.4984, top5_acc=0.7869, top3_acc=0.7049 macro_f1=0.2474\n",
      "VAL: top1_acc=0.4951, top5_acc=0.7803, top3_acc=0.6820 macro_f1=0.2391\n",
      "VAL: top1_acc=0.4852, top5_acc=0.7869, top3_acc=0.6623 macro_f1=0.2357\n",
      "Early stopping at epoch 165\n",
      "HID64_DO0.35_SEED3__X_edgeAttr_lattice_oms_AtomicNumber_structsym TEST: top1_acc=0.4510, top5_acc=0.7647, top3_acc=0.6797 macro_f1=0.2827\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__X_edgeAttr_lattice_oms_AtomicNumber_structsym\"\n",
    "    print(f\"\\n===== Training config: {config_name} =====\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    # ==================== Model ====================\n",
    "    model = MetalSaltGNN_v2(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes, \n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=0.0001)\n",
    "    checkpoint_name = f\"tmp2/Metal_salts_{config_name}.pt\"\n",
    "    best_metric = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 50\n",
    "    eval_every = 5\n",
    "\n",
    "    for epoch in range(1, 1001):\n",
    "        train(model, train_loader, criterion, optimizer, device, \"metal_salts\")\n",
    "        if epoch % eval_every == 0:\n",
    "            res = evaluate(model, val_loader, device, \"metal_salts\")\n",
    "            print(f\"VAL: top1_acc={res['top1_acc']:.4f}, top5_acc={res['top5_acc']:.4f}, top3_acc={res['top3_acc']:.4f} macro_f1={res['macro_f1']:.4f}\")\n",
    "            \n",
    "            if res[\"top5_acc\"] > best_metric:\n",
    "                best_metric = res[\"top5_acc\"]\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(model.state_dict(), checkpoint_name)\n",
    "            else:\n",
    "                epochs_no_improve += eval_every\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_name))\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "    results.append({**res_test, 'config': config_name})\n",
    "    print(f\"{config_name} TEST: top1_acc={res_test['top1_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f} macro_f1={res_test['macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25722051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[92, 4], edge_index=[2, 124], edge_attr=[124, 1], lattice=[3, 3], metal_salts=[1, 667], ligands=[2, 1743], solvents=[1, 139], oms=[1, 1], atomic_one_hot=[120], cordinates=[96], space_group_number=[231], crystal_system=[7], porosity=[8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db04f4",
   "metadata": {},
   "source": [
    "### 4) Load and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22757017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluating config: HID64_DO0.35_SEED1__X_edgeAttr_lattice_oms_AtomicNumber_structsym =====\n",
      "HID64_DO0.35_SEED1__X_edgeAttr_lattice_oms_AtomicNumber_structsym TEST: top10_acc=0.8954, top5_acc=0.7614, top3_acc=0.6601, macro_f1=0.2764\n",
      "\n",
      "===== Evaluating config: HID64_DO0.35_SEED2__X_edgeAttr_lattice_oms_AtomicNumber_structsym =====\n",
      "HID64_DO0.35_SEED2__X_edgeAttr_lattice_oms_AtomicNumber_structsym TEST: top10_acc=0.8824, top5_acc=0.7484, top3_acc=0.6503, macro_f1=0.2492\n",
      "\n",
      "===== Evaluating config: HID64_DO0.35_SEED3__X_edgeAttr_lattice_oms_AtomicNumber_structsym =====\n",
      "HID64_DO0.35_SEED3__X_edgeAttr_lattice_oms_AtomicNumber_structsym TEST: top10_acc=0.8954, top5_acc=0.7647, top3_acc=0.6797, macro_f1=0.2827\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for seed in number_of_runs:\n",
    "    config_name = f\"HID{hidden_dim}_DO{dropout}_SEED{seed}__X_edgeAttr_lattice_oms_AtomicNumber_structsym\"\n",
    "    print(f\"\\n===== Evaluating config: {config_name} =====\")\n",
    "    \n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    model = MetalSaltGNN_v2(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        lattice_in_dim=lattice_in_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes, \n",
    "        num_gnn_layers=4,\n",
    "        num_lattice_layers=2,\n",
    "        num_mlp_layers=2,\n",
    "        dropout=dropout,\n",
    "        use_batchnorm=True\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint_name = f\"tmp2/Metal_salts_{config_name}.pt\"\n",
    "    # Carica best model e valuta su test\n",
    "    checkpoint = torch.load(checkpoint_name, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    res_test = evaluate(model, test_loader, device, \"metal_salts\")\n",
    "\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'top1_acc': res_test['top1_acc'],\n",
    "        'top10_acc': res_test['top10_acc'],\n",
    "        'top5_acc': res_test['top5_acc'],\n",
    "        'top3_acc': res_test['top3_acc'],\n",
    "        'macro_f1': res_test['macro_f1']\n",
    "    })\n",
    "    print(f\"{config_name} TEST: top10_acc={res_test['top10_acc']:.4f}, top5_acc={res_test['top5_acc']:.4f}, top3_acc={res_test['top3_acc']:.4f}, macro_f1={res_test['macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f6466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bde3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cc751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95f257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6580e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "set_seed(seed=42)\n",
    "\n",
    "data_in = load_pyg_obj(path_to_mdb=\"../../data/mof_syncondition_data/\")\n",
    "dataset = fix_target_shapes(data_in, \"metal_salts\")\n",
    "dataset = remove_unused_onehot_columns(dataset, \"metal_salts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d990e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf292fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baaf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = torch.nn.functional.one_hot(torch.tensor(idx), num_classes=len(unique_atomic_numbers)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed39174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e476ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7bf471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f2a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4375f232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884932c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7852b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa08e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55aa79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba51402",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3fa48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(atom_num,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71524153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[0,8,0,0,0,..,32,0,4,0,0,0,0,0,0] # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc6622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.data import atomic_numbers\n",
    "\n",
    "atomic_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aa486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc224fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a, _ = np.unique(filter_metals(d.x.numpy()[:,0].astype(int)), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f77c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metals(d.x.numpy()[:,0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofstructure.mofdeconstructor import transition_metals\n",
    "\n",
    "\n",
    "from ase.data import atomic_numbers\n",
    "\n",
    "len(transition_metals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.data import atomic_numbers\n",
    "\n",
    "atomic_numbers\n",
    "\n",
    "\n",
    "[atomic_numbers[i] for i in transition_metals()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86a05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18032669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "unique_atomic_numbers = np.unique(atomic_numb)\n",
    "atomic_to_idx = {num: idx for idx, num in enumerate(unique_atomic_numbers)}\n",
    "\n",
    "for data in dataset:\n",
    "    node_features = data.x.numpy()\n",
    "    atomic_number = filter_metals(node_features[:, 0].astype(int))\n",
    "    atomic_number = np.unique(atomic_number)[0]\n",
    "    idx = atomic_to_idx[atomic_number]\n",
    "    one_hot = torch.nn.functional.one_hot(torch.tensor(idx), num_classes=len(unique_atomic_numbers)).float()\n",
    "    data.atomic_one_hot = one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.data import chemical_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cd249",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_symbols[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d770a8",
   "metadata": {},
   "source": [
    "# real word experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b92e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mofstructure import structure, mofdeconstructor\n",
    "from mofstructure.filetyper import load_iupac_names\n",
    "from fairmofsyncondition.read_write import cheminfo2iupac, coords_library, filetyper\n",
    "from ase.data import atomic_numbers\n",
    "from ase.io import read\n",
    "import torch\n",
    "\n",
    "\n",
    "inchi_corrector = {\n",
    "    \"FDTQOZYHNDMJCM-UHFFFAOYSA-N\":\"benzene-1,4-dicarboxylic acid\"\n",
    "}\n",
    "def get_ligand_iupacname(ligand_inchi):\n",
    "    print(ligand_inchi)\n",
    "    name = load_iupac_names().get(ligand_inchi, None)\n",
    "    if name is None:\n",
    "        pubchem = cheminfo2iupac.pubchem_to_inchikey(ligand_inchi, name='inchikey')\n",
    "        if pubchem is None:\n",
    "            name = inchi_corrector.get(ligand_inchi, ligand_inchi)\n",
    "        else:\n",
    "            pubchem.get('iupac_name', ligand_inchi)\n",
    "    return name\n",
    "\n",
    "\n",
    "def load_system(filename):\n",
    "    \"\"\"\n",
    "    A function to extract\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    os.makedirs('LigandsXYZ', exist_ok=True)\n",
    "    ase_data = read(filename)\n",
    "    structure_data = structure.MOFstructure(ase_atoms=ase_data)\n",
    "    _, ligands = structure_data.get_ligands()\n",
    "\n",
    "    inchikeys = [ligand.info.get('inchikey') for ligand in ligands]\n",
    "    for inchi, ligand in zip(inchikeys, ligands):\n",
    "        ligand.write(f'LigandsXYZ/{inchi}.xyz')\n",
    "    ligands_names = [get_ligand_iupacname(i) for i in inchikeys]\n",
    "    general = structure_data.get_oms()\n",
    "    oms = general.get('has_oms')\n",
    "    metal_symbols = general.get('metals')\n",
    "    metals_atomic_number = [atomic_numbers[i] for i in metal_symbols]\n",
    "    torch_data = coords_library.ase_to_pytorch_geometric(ase_data)\n",
    "    oms = torch.tensor([1 if  oms else 0], dtype=torch.int16)\n",
    "    torch_data.oms = oms\n",
    "    data['general'] = general\n",
    "    return torch_data, metals_atomic_number, inchikeys, ligands_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b40a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): Zn(1); Metal was disconnected\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): Zn(1); Metal was disconnected\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDTQOZYHNDMJCM-UHFFFAOYSA-N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/miniconda3/envs/fairmof/lib/python3.11/site-packages/pymatgen/io/cif.py:1606: FutureWarning: We strongly discourage using implicit binary/text `mode`, and this would not be allowed after 2025-06-01. I.e. you should pass t/b in `mode`.\n",
      "  with zopen(filename, mode=mode) as file:\n"
     ]
    }
   ],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"EDUSIF.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8517eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1); C(3)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1); C(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGFJDEHFNMWYBD-OWOJBTEDSA-N\n",
      "VIORWCNXRPKALR-UHFFFAOYSA-N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 16:21:27,251 - INFO - 'PUGREST.NotFound: No CID found that matches the given InChI key'\n",
      "/home/antonio/miniconda3/envs/fairmof/lib/python3.11/site-packages/pymatgen/io/cif.py:1606: FutureWarning: We strongly discourage using implicit binary/text `mode`, and this would not be allowed after 2025-06-01. I.e. you should pass t/b in `mode`.\n",
      "  with zopen(filename, mode=mode) as file:\n"
     ]
    }
   ],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"Zn2C43N6H29O8.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f30b5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n",
      "==============================\n",
      "*** Open Babel Warning  in InChI code\n",
      "  #1 :Accepted unusual valence(s): O(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESFABUZNSNZRT-UHFFFAOYSA-N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 16:21:54,445 - INFO - 'PUGREST.NotFound: No CID found that matches the given InChI key'\n"
     ]
    }
   ],
   "source": [
    "torch_data, metal_atomic_number, inch, lig = load_system(\"ZnC5HO5.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17791fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10c3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True None\n",
      "Reading input file: tmp.cssr\n",
      "Radii analysis: the smallest atom r = 1.09 while the largest atoms r = 1.7.\n",
      "Box dimensions:\n",
      "  va=(6.862800 0 0)\n",
      "  vb=(0.000000 25.902900 0)\n",
      "  vc=(0.000000 -12.951450 22.432569)\n",
      "\n",
      "Total particles = 1602\n",
      "\n",
      "Internal grid size = (3 10 9)\n",
      "\n",
      "Using voro++ with radii for particles.\n",
      "Performing Voronoi decomposition.\n",
      "Volume check:\n",
      "  Total domain volume  = 3987.757607\n",
      "  Total Voronoi volume = 3987.757607\n",
      "Voronoi decomposition finished. Rerouting Voronoi network information.\n",
      "Finished rerouting information.\n",
      "Voronoi network with 9598 nodes. 891 of them are accessible. \n",
      "\n",
      "Finding channels and pockets in Dijkstra network of 9598 node(s). 891 are expected to compose pores.\n",
      "Analyzed and assigned 9598 nodes.\n",
      "Identified 3 channels and 0 pockets.\n",
      "891 nodes assigned to pores. \n",
      "Radii analysis: the smallest atom r = 1.09 while the largest atoms r = 1.7.\n",
      "Box dimensions:\n",
      "  va=(6.862800 0 0)\n",
      "  vb=(0.000000 25.902900 0)\n",
      "  vc=(0.000000 -12.951450 22.432569)\n",
      "\n",
      "Total particles = 1602\n",
      "\n",
      "Internal grid size = (3 10 9)\n",
      "\n",
      "Using voro++ with radii for particles.\n",
      "Performing Voronoi decomposition.\n",
      "Volume check:\n",
      "  Total domain volume  = 3987.757607\n",
      "  Total Voronoi volume = 3987.757607\n",
      "Voronoi decomposition finished. Rerouting Voronoi network information.\n",
      "Finished rerouting information.\n",
      "Voronoi network with 9598 nodes. 891 of them are accessible. \n",
      "\n",
      "Finding channels and pockets in Dijkstra network of 9598 node(s). 891 are expected to compose pores.\n",
      "Analyzed and assigned 9598 nodes.\n",
      "Identified 3 channels and 0 pockets.\n",
      "891 nodes assigned to pores. \n",
      "Box dimensions:\n",
      "  va=(6.862800 0 0)\n",
      "  vb=(0.000000 25.902900 0)\n",
      "  vc=(0.000000 -12.951450 22.432569)\n",
      "\n",
      "Total particles = 162\n",
      "\n",
      "Internal grid size = (2 5 4)\n",
      "\n",
      "Using voro++ with radii for particles.\n",
      "Performing Voronoi decomposition.\n",
      "Volume check:\n",
      "  Total domain volume  = 3987.757607\n",
      "  Total Voronoi volume = 3987.757607\n",
      "Voronoi decomposition finished. Rerouting Voronoi network information.\n",
      "Finished rerouting information.\n"
     ]
    }
   ],
   "source": [
    "from mofstructure.structure import MOFstructure\n",
    "convert_metals = {j:i for i,j in enumerate(mofdeconstructor.transition_metals()[1:])}\n",
    "\n",
    "\n",
    "# Parte 1: atomic one-hot\n",
    "# =======================\n",
    "node_features = d.x.numpy()\n",
    "atom_num = node_features[:, 0].astype(int)\n",
    "a, b = np.unique(atom_num, return_counts=True)\n",
    "emb = torch.zeros(120)\n",
    "for aa, bb in zip(a, b):\n",
    "    emb[aa] = bb\n",
    "d.atomic_one_hot = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 2: struttura ASE\n",
    "# =======================\n",
    "ase_atoms = pytorch_geometric_to_ase(d)\n",
    "stru = MOFstructure(ase_atoms)\n",
    "pymat = AseAtomsAdaptor.get_structure(ase_atoms)\n",
    "\n",
    "# =======================\n",
    "# Parte 3: OMS\n",
    "# =======================\n",
    "emb = torch.zeros(96)\n",
    "tmp_dict = dict()\n",
    "for i in stru.get_oms()[\"metal_info\"]:\n",
    "    cord = i[\"coordination_number\"]\n",
    "    metal = i[\"metal\"]\n",
    "\n",
    "    if metal in tmp_dict:\n",
    "        if cord > tmp_dict[metal]:\n",
    "            tmp_dict[metal] = cord\n",
    "    else:\n",
    "        tmp_dict[metal] = cord\n",
    "\n",
    "for i, j in tmp_dict.items():\n",
    "    emb[convert_metals[i]] = j\n",
    "d.cordinates = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 4: spazio e sistema cristallino\n",
    "# =======================\n",
    "sga = SpacegroupAnalyzer(pymat)\n",
    "space_group_number = sga.get_space_group_number()\n",
    "emb = torch.zeros(231)\n",
    "emb[space_group_number] = 1\n",
    "d.space_group_number = emb\n",
    "\n",
    "get_crystal_system = sga.get_crystal_system()\n",
    "emb = torch.zeros(7)\n",
    "emb[convert_struct[get_crystal_system]] = 1\n",
    "d.crystal_system = emb\n",
    "\n",
    "# =======================\n",
    "# Parte 5: altri attributi\n",
    "# =======================\n",
    "###\n",
    "to get oms\n",
    "stru.get_oms()[\"has_oms\"]\n",
    "\n",
    "d.oms = d.oms.view(1, 1).float()\n",
    "\n",
    "por = stru.get_porosity()\n",
    "por = list(por.values())\n",
    "d.porosity = torch.tensor(por)\n",
    "\n",
    "d.modified_scherrer = None\n",
    "d.microstrain = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7de6c1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZnC13H11O8NP\n",
      "ZnCl2·4H2O\n",
      "Zn(CH3COO)2·2H2O\n",
      "ZnSO4.7H2O\n",
      "ZnSiF6\n"
     ]
    }
   ],
   "source": [
    "pred = model(d.to(device))\n",
    "prx = \"Zn\"\n",
    "\n",
    "c = 0\n",
    "for i in pred.argsort()[0]:\n",
    "    a = filetyper.category_names()[\"metal_salts\"][i.item()]\n",
    "    \n",
    "    if a[:2] == prx:\n",
    "        print(a)\n",
    "        c = c +1 \n",
    "        \n",
    "    if c == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e96d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ad21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairmof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
